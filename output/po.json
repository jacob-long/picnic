{
  "update": "2025-09-22",
  "content": [
    {
      "journal_full": "International Journal of Public Opinion Research",
      "journal_short": "IJPOR",
      "articles": [
        {
          "title": "Depression, Populism, and Presidential Approval",
          "authors": "Matthew A Baum, James N Druckman, Katherine Ognyanova, David Lazer, Roy H Perlis",
          "abstract": "Is there a relationship between depression and political evaluations? Building on existing work, we argue that experiencing depressive symptoms will positively correlate with supporting a populist politician and negatively correlate with supporting a nonpopulist officeholder. We evaluate these predictions with data from the United States, focusing on Donald Trump and Joe Biden. Our data are consistent with our hypotheses, and, as expected, we find particularly strong relationships for Democratic respondents. The results highlight the importance of considering mental health when studying the approval of politicians both in and out of office. We conclude with a discussion of next steps for a research agenda on depression and political evaluations.",
          "url": "https://doi.org/10.1093/ijpor/edaf050",
          "doi": "https://doi.org/10.1093/ijpor/edaf050",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Elections, Public Opinion and Parties",
      "journal_short": "JEPOP",
      "articles": [
        {
          "title": "Voting for incumbents in the Caribbean: a test of three hypotheses",
          "authors": "Lucas Perelló, Natalie Chaudhuri",
          "url": "https://doi.org/10.1080/17457289.2025.2555840",
          "doi": "https://doi.org/10.1080/17457289.2025.2555840",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Official Statistics",
      "journal_short": "JOS",
      "articles": [
        {
          "title": "Why are Measures of Aggregate Hours Worked by the Unincorporated Self-Employed So Volatile?",
          "authors": "Cindy Michelle Cunningham, Sabrina Wulff Pabilonia",
          "abstract": "Self-employment hours, as measured using the Current Population Survey (CPS), occasionally vary widely from one quarter to the next, and these variations can result in large fluctuations in measures of quarterly labor productivity produced by the U.S. Bureau of Labor Statistics. In this paper, we examine whether certain aspects of the CPS sample design, including sample weighting, the rotation group framework, imputation methods, and proxy-reporting, are associated with these large variations. We find that volatility in the number of self-employed is much higher when comparing changes in self-employment among workers who are not in the sample in two consecutive quarters compared with those who are in the sample in consecutive quarters. In addition, proxy-responses make larger contributions to self-employment growth in more quarters than do self-responses, and month-to-month changes in class-of-worker status occurring with transitions between proxy- and self-responses in the CPS panel contribute to increased volatility. Finally, imputed self-employment is more volatile than nonimputed self-employment, but there are few imputed responses.",
          "url": "https://doi.org/10.1177/0282423x251354908",
          "doi": "https://doi.org/10.1177/0282423x251354908",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Survey Statistics and Methodology",
      "journal_short": "JSSAM",
      "articles": [
        {
          "title": "Randomized, Controlled Trial Comparing Household Response and Completion Rates Using 1 and 2 US Dollar Unconditional Incentives in A Mail Push-to-Web Survey",
          "authors": "Jon Agley, Tiffany Neal, Mariah Benham, Lilian Golzarri-Arroyo, Naomi Swiezy",
          "abstract": "Household surveys are an important means of obtaining standardized data; unfortunately, response rates have been declining for decades. Evidence based on social exchange theory supports the use of small, unconditional monetary incentives (pre-incentives) to increase survey response and completion rates. However, the optimal pre-incentive amount is unclear. Our project team was contracted to conduct a large survey (census) of all households in Indiana at which an individual with a developmental disability who was on the waitlist for certain state-based services resided. In the absence of a clear answer from the literature about what pre-incentive amount to use, we preregistered a sub-study to obtain clarity. We conducted a randomized controlled trial comparing a $1 cash pre-incentive to a $2 cash pre-incentive in a large, mail push-to-web household survey in the midwestern US, examining both response rates and completion rates (&amp;gt;80 percent of the survey). We hypothesized that a $2 pre-incentive would result in significantly more responses and completed surveys than a $1 pre-incentive. Using 1:1 blinded allocation, 6,525 households were randomized to receive either a $1 or $2 cash pre-incentive. All other procedures were identical between study arms. Of the 960 valid responses, 467 were from Arm 1 ($1) and 493 were from Arm 2 ($2). Of those, there were 798 complete responses (&amp;gt;80 percent of the instrument). We did not find sufficient evidence to conclude that there was a difference in either response (OR = 1.07, p = .361, 95 percent CI [0.929, 1.223]) or completion (OR = 1.07, p = .362, 95 percent CI [0.924, 1.242]) rates depending on the amount of pre-incentive included in the invitation. Although we provide multiple caveats and encourage caution when interpreting these findings, we suggest that individuals planning to use a small pre-incentive to encourage survey responses should not by default assume that a $2 incentive is superior to a $1 incentive.",
          "url": "https://doi.org/10.1093/jssam/smaf020",
          "doi": "https://doi.org/10.1093/jssam/smaf020",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Social Science Computer Review",
      "journal_short": "SSCR",
      "articles": [
        {
          "title": "Leveraging VLLMs for Visual Clustering: Image-to-Text Mapping Shows Increased Semantic Capabilities and Interpretability",
          "authors": "Luigi Arminio, Matteo Magnani, Matías Piqueras, Luca Rossi, Alexandra Segerberg",
          "abstract": "As visual content becomes increasingly prominent on social media, automated image categorization is vital for computational social science efforts to identify emerging visual themes and narratives in online debates. However, the methods based on convolutional neural networks (CNNs) currently used in the field are unable to fully capture the connotative meaning of images, and struggle to produce easily interpretable clusters. In response to these challenges, we test an approach that leverages the ability of Vision-and-Large-Language-Models (VLLMs) to generate image descriptions that incorporate connotative interpretations of the input images. In particular, we use a VLLM to generate connotative textual descriptions of a set of images related to climate debate, and cluster the images based on these textual descriptions. In parallel, we cluster the same images using a more traditional approach based on CNNs. In doing so, we compare the connotative semantic validity of clusters generated using VLLMs with those produced using CNNs, and assess their interpretability. The results show that the approach based on VLLMs greatly improves the quality score for connotative clustering. Moreover, VLLM-based approaches, leveraging textual information as a step towards clustering, offer a high level of interpretability of the results.",
          "url": "https://doi.org/10.1177/08944393251376703",
          "doi": "https://doi.org/10.1177/08944393251376703",
          "filter": 0
        },
        {
          "title": "Demystifying Misconceptions in Social Bots Research",
          "authors": "Stefano Cresci, Kai-Cheng Yang, Angelo Spognardi, Roberto Di Pietro, Filippo Menczer, Marinella Petrocchi",
          "abstract": "Research on social bots aims at advancing knowledge and providing solutions to one of the most debated forms of online manipulation. Yet, social bot research is plagued by widespread biases, hyped results, and misconceptions that set the stage for ambiguities, unrealistic expectations, and seemingly irreconcilable findings. Overcoming such issues is instrumental toward ensuring reliable solutions and reaffirming the validity of the scientific method. Here, we discuss a broad set of consequential methodological and conceptual issues that affect current social bots research, illustrating each with examples drawn from recent studies. More importantly, we demystify common misconceptions, addressing fundamental points on how social bots research is discussed. Our analysis surfaces the need to discuss research about online disinformation and manipulation in a rigorous, unbiased, and responsible way. This article bolsters such effort by identifying and refuting common fallacious arguments used by both proponents and opponents of social bots research, as well as providing directions toward sound methodologies for future research.",
          "url": "https://doi.org/10.1177/08944393251376707",
          "doi": "https://doi.org/10.1177/08944393251376707",
          "filter": 0
        }
      ],
      "articles_hidden": []
    }
  ]
}
