{
  "update": "2025-10-09",
  "content": [
    {
      "journal_full": "Behavior Research Methods",
      "journal_short": "BRM",
      "articles": [
        {
          "title": "Building a construct-valid battery of performance and self-report indicators of sustained attention consistency",
          "authors": "Matthew S. Welhaf, Matt E. Meier, Michael J. Kane",
          "abstract": "Previous work has argued that the ability to sustain attention consistency can be best modeled as the individual-difference covariation in objective performance-based measures (e.g., reaction-time [RT] variability; accuracy) and self-report measures of task-unrelated thought (TUT). Latent variable studies demonstrate that a general, higher-order attention consistency factor correlates more strongly with nomological network constructs than do either lower-order, measurement-specific factors. The present study aimed to replicate and extend this measurement approach by building a construct-valid battery of sustained attention consistency tasks and testing associations with the conative factors of task interest and success motivation. We analyzed data from 402 subjects who completed a battery of seven attention-consistency functions and found that the hierarchical model provided an adequate fit to the data. Further, attention-consistency associations with motivation and interest, while evident with the lower-order factors, were again stronger with the general higher-order factor (and each conative factor predicted unique variance in general attention consistency in structural regression models). We also refined our task battery by removing poor-performing indicators and demonstrated similar patterns of correlations among the attention and conative factors. We suggest that studies examining attention consistency should use a combination of performance and self-report indicators to capture its individual-differences variation in the most construct valid way. We finally provide recommendations on which tasks and measures might be most useful when measuring sustained attention consistency in future research.",
          "url": "https://doi.org/10.3758/s13428-025-02798-w",
          "doi": "https://doi.org/10.3758/s13428-025-02798-w",
          "filter": 0
        },
        {
          "title": "Testing thought-probe frequency for measuring mind-wandering along with vigilance and cognitive control loss: A study with the ANTI-Vea task",
          "authors": "María Julieta Aguirre, Pablo Barttfeld, Elisa Martín-Arévalo, Juan Lupiáñez, Fernando G. Luna",
          "url": "https://doi.org/10.3758/s13428-025-02808-x",
          "doi": "https://doi.org/10.3758/s13428-025-02808-x",
          "filter": 0
        },
        {
          "title": "Movement tracking of psychological processes: A tutorial using mousetrap",
          "authors": "Dirk U. Wulff, Pascal J. Kieslich, Felix Henninger, Jonas M. B. Haslbeck, Michael Schulte-Mecklenbeck",
          "abstract": "Movement tracking is a novel process-tracing method that promises unique access to the temporal dynamics of psychological processes. The method involves high-resolution tracking of a hand or handheld device (e.g., a computer mouse) while it is used to make a choice. In contrast to other process-tracing methods, which mostly focus on information acquisition, movement tracking focuses on the processes of information integration and preference formation. In this article, we present a tutorial on movement tracking of psychological processes with the mousetrap R package. We address all steps of the research process, from design to interpretation, with a particular focus on data processing and analysis and featuring both established and novel approaches. Using a representative working example, we demonstrate how the various steps of movement-tracking analysis can be implemented with mousetrap and provide thorough explanations of their theoretical background and interpretation. Finally, we present a list of recommendations to assist researchers in addressing their own research questions using movement tracking of psychological processes.",
          "url": "https://doi.org/10.3758/s13428-025-02695-2",
          "doi": "https://doi.org/10.3758/s13428-025-02695-2",
          "filter": 0
        },
        {
          "title": "Towards scalable and reliable coding of semantic property norms: ChatGPT vs. an improved AC-PLT",
          "authors": "Diego Ramos, Sebastián Moreno, Enrique Canessa, Sergio E. Chaigneau",
          "url": "https://doi.org/10.3758/s13428-025-02838-5",
          "doi": "https://doi.org/10.3758/s13428-025-02838-5",
          "filter": 0
        },
        {
          "title": "Crowdsourced and AI-generated age-of-acquisition (AoA) norms for vocabulary in print: Extending the Kuperman et al. (2012) norms",
          "authors": "Clarence Green, Anthony Pak-Hin Kong, Marc Brysbaert, Kathleen Keogh",
          "abstract": "This paper revisits the age-of-acquisition (AoA) norms of Kuperman et al. (2012). Three studies were conducted. Study 1 reports a crowdsourcing ‘megastudy’ obtaining 790,024 estimates from participants with the age they could first read and write 11,074 early acquired words from Kuperman et al. (2012). The study aimed to differentiate between oral language receptive AoA and print-based AoA. The results correlate well with the original estimates, offering, as hypothesized, higher AoAs for reading/writing. These are released as supplements to the original norms. Study 2 explored the potential of large language models (LLMs), specifically GPT-4o, to replicate these crowdsourced AoA estimates. The findings indicated a strong correlation between AI-generated estimates and human judgments, showing the utility of AI in estimating AoA and developing norms for psycholinguistic and educational research in lieu of crowdsourcing. Study 3 leveraged AI to extend estimates to all well-known words in Kuperman et al. (2012) and the English Crowdsourcing Project (ECP). Study 3 also investigated a trained model fine-tuned on 2000 ratings from Kuperman et al. (2012). Fine-tuning increased alignment with human ratings, though comparisons with untrained models suggested that fine-tuning is not essential in English for obtaining useful AoA estimates. Both trained and untrained AI-generated norms correlated highly with human ratings and performed well in accounting for word processing times and accuracy in regressions. Uses and limitations of the AI estimates are discussed. All resources are made available in the Open Science Framework and can be used freely for research and education.",
          "url": "https://doi.org/10.3758/s13428-025-02843-8",
          "doi": "https://doi.org/10.3758/s13428-025-02843-8",
          "filter": 0
        },
        {
          "title": "Can you beat the music? Validation of a gamified rhythmic training in children with ADHD",
          "authors": "Kevin Jamey, Hugo Laflamme, Nicholas E. V. Foster, Simon Rigoulot, Sarah Lippé, Sonja A. Kotz, Simone Dalla Bella",
          "url": "https://doi.org/10.3758/s13428-025-02802-3",
          "doi": "https://doi.org/10.3758/s13428-025-02802-3",
          "filter": 0
        },
        {
          "title": "Applying Bayesian checks of cancellation axioms for interval scaling in limited samples",
          "authors": "Sanford R. Student, Wyatt S. Read",
          "abstract": "Interval scales are frequently assumed in educational and psychological research involving latent variables, but are rarely verified. This paper outlines methods for investigating the interval scale assumption when fitting the Rasch model to item response data. We study a Bayesian method for evaluating an item response dataset’s adherence to the cancellation axioms of additive conjoint measurement under the Rasch model, and compare the extent to which the axiom of double cancellation holds in the data at sample sizes of 250 and 1000 with varying test lengths, difficulty spreads, and levels of adherence to the Rasch model in the data-generating process. Because the statistic produced by the procedure is not directly interpretable as an indicator of whether an interval scale can be established, we develop and evaluate procedures for bootstrapping a null distribution of violation rates against which to compare results. At a sample size of 250, the method under investigation is not well powered to detect the violations of interval scaling that we simulate, but the procedure works quite consistently at N = 1000. That is, at moderate but achievable sample sizes, empirical tests for interval scaling are indeed possible.",
          "url": "https://doi.org/10.3758/s13428-025-02844-7",
          "doi": "https://doi.org/10.3758/s13428-025-02844-7",
          "filter": 0
        },
        {
          "title": "A systematic review of latent class analysis in psychology: Examining the gap between guidelines and research practice",
          "authors": "Angela Sorgente, Rossella Caliciuri, Matteo Robba, Margherita Lanz, Bruno D. Zumbo",
          "abstract": "Latent class analysis (LCA) can help identify unobserved classes of individuals in a population based on collected categorical data. It is commonly used in psychology to test hypotheses about sources of heterogeneity and class characteristics. However, careful decision-making is required in the modeling process. Its flexibility may explain why it is becoming more commonly used in psychology; however, it also highlights that there are many decision points in the modeling process, thus warranting a systematic literature review to document the use of LCA in psychology, mapping both the prevalence and quality of LCA studies. This systematic review followed the PRISMA guidelines and involved a comprehensive search across multiple databases, yielding 7,580 records related to latent class analysis. After removing duplicates and selecting a representative subsample, 377 documents were assessed for eligibility. Of these, 251 publications (comprising 313 LCAs) met the inclusion and exclusion criteria and were reviewed for this study. Each study was meticulously coded to map how the authors performed and reported each step of the LCA. Our analysis of these studies, in comparison with published guidelines, revealed notable discrepancies in how LCA is applied and reported. To support researchers in enhancing the quality of future LCA applications, we summarize key recommendations in a final section that outlines best practices for future LCA applications. The findings indicate a growing use of LCA in psychology but also highlight the need for greater methodological rigor and transparency in its implementation.",
          "url": "https://doi.org/10.3758/s13428-025-02812-1",
          "doi": "https://doi.org/10.3758/s13428-025-02812-1",
          "filter": 0
        },
        {
          "title": "Novel Prototype and Exemplar (NPE) database: A set of 2700 novel 3D images with viewpoint and shape variations",
          "authors": "Zhaochenze Li, Tongshu Yang, Yanli Huang, Yang Liu, Jiushu Xie",
          "url": "https://doi.org/10.3758/s13428-025-02837-6",
          "doi": "https://doi.org/10.3758/s13428-025-02837-6",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Computers in Human Behavior",
      "journal_short": "CHB",
      "articles": [
        {
          "title": "“I would have gone to the original source”: Emerging and established readers’ cognitive and metacognitive strategies during online evaluation",
          "authors": "Julie A. Corrigan, Elena Forzani",
          "url": "https://doi.org/10.1016/j.chb.2025.108818",
          "doi": "https://doi.org/10.1016/j.chb.2025.108818",
          "filter": 0
        },
        {
          "title": "How audiences make sense of deepfake resurrections: A multilevel analysis of realism, ethics, and cultural meaning",
          "authors": "María T. Soto-Sanfiel, Qiaofei Wu",
          "url": "https://doi.org/10.1016/j.chb.2025.108822",
          "doi": "https://doi.org/10.1016/j.chb.2025.108822",
          "filter": 0
        },
        {
          "title": "Digital Assets in Mental Accounting: How Cryptocurrency and NFTs Influence Charitable Choices",
          "authors": "Claudio Schapsis, Dorin Micu, Nikki Wingate",
          "url": "https://doi.org/10.1016/j.chb.2025.108820",
          "doi": "https://doi.org/10.1016/j.chb.2025.108820",
          "filter": 0
        },
        {
          "title": "How Gaming Goal Pursuit and Expert-Rated Computer Game Features Interact to Affect Human Game Use Behavior",
          "authors": "Gen-Yih Liao, Shih-I Tai, Ng Nga Yan, T.C.E. Cheng, Ching-I Teng",
          "url": "https://doi.org/10.1016/j.chb.2025.108819",
          "doi": "https://doi.org/10.1016/j.chb.2025.108819",
          "filter": 0
        },
        {
          "title": "Public attitudes towards police use of AI-driven face recognition technology",
          "authors": "Anna Sagana, Mengying Zhang, Melanie Sauerland",
          "url": "https://doi.org/10.1016/j.chb.2025.108821",
          "doi": "https://doi.org/10.1016/j.chb.2025.108821",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Experimental Social Psychology",
      "journal_short": "JESP",
      "articles": [
        {
          "title": "Feedback to video stimuli: A novel paradigm for manipulating existential isolation",
          "authors": "Matthew Espinosa, Cathy R. Cox",
          "url": "https://doi.org/10.1016/j.jesp.2025.104837",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104837",
          "filter": 0
        },
        {
          "title": "Beyond the basic six, static, and WERID: Exploring the range of emotions conveyed by facial expressions",
          "authors": "Zhihe Pan, Hweemin Tan, Siqi Liu, Xia Fang",
          "url": "https://doi.org/10.1016/j.jesp.2025.104836",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104836",
          "filter": 0
        },
        {
          "title": "Intentions versus outcomes: Determinants of costly third-party interventions in fairness maintenance",
          "authors": "Mei Chen, Ruqian Zhang, Yangzhuo Li, Jieqiong Liu, Xianchun Li",
          "url": "https://doi.org/10.1016/j.jesp.2025.104838",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104838",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Personality and Social Psychology",
      "journal_short": "JPSP",
      "articles": [
        {
          "title": "Beyond hypothetical trolleys: Moral choices and motivations in a real-life sacrificial dilemma.",
          "authors": "Dries H. Bostyn, Marie-Céline Gouwy, Elias De Craene, Caro Vanmechelen, Joyce Scheirlinckx, Tassilo T. Tissot, Ruben Van Severen, Daphne van den Bogaard, Milena Waterschoot, Fien Geenen, Hilde Depauw, Jakke Coenye, Juliette Taquet, Xinyi Xu, Kim Dierckx, Stefaan Van Damme, Alain Van Hiel, Arne Roets",
          "url": "https://doi.org/10.1037/pspa0000463",
          "doi": "https://doi.org/10.1037/pspa0000463",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Multivariate Behavioral Research",
      "journal_short": "MBR",
      "articles": [
        {
          "title": "Standardized Estimates of Second-Order Latent Growth Models: A Comparison of Alternative Latent-Standardization Methods",
          "authors": "Yifan Wang, Zhonglin Wen, Kit-Tai Hau, Tonglin Jin",
          "url": "https://doi.org/10.1080/00273171.2025.2543240",
          "doi": "https://doi.org/10.1080/00273171.2025.2543240",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Organizational Research Methods",
      "journal_short": "ORM",
      "articles": [
        {
          "title": "Understanding Relative Differences with Magnitude-Based Hypotheses: A Methodological Conceptualization and Data Illustration",
          "authors": "Dane P. Blevins, David J. Skandera, Roberto Ragozzino",
          "abstract": "Our paper provides a conceptualization of magnitude-based hypotheses (MBHs). We define an MBH as a specific type of hypothesis that tests for relative differences in the independent impact (i.e., effect size difference) of at least two explanatory variables on a given outcome. We reviewed 1,715 articles across eight leading management journals and found that nearly 10% (165) of articles feature an MBH, employing 41 distinct methodological approaches to test them. However, approximately 40% of these papers show missteps in the post-estimation process required to evaluate MBHs. To address this issue, we offer a conceptual framework, an empirical illustration using Bayesian analysis and frequentist statistics, and a decision-tree guideline that outlines key steps for evaluating MBHs. Overall, we contribute a framework for applying MBHs, demonstrating how they can shift theoretical inquiry from binary questions of whether an effect exists, to more comparative questions about how much a construct matters,compared to what, and under which conditions.",
          "url": "https://doi.org/10.1177/10944281251377139",
          "doi": "https://doi.org/10.1177/10944281251377139",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Personality and Social Psychology Bulletin",
      "journal_short": "PSPB",
      "articles": [
        {
          "title": "The Underestimation of Transgender Women’s Vulnerability to Workplace Sexual Harassment",
          "authors": "Bryn Bandt-Law, Nathan N. Cheek, Jessica J. Glazier, Kristina R. Olson, Cheryl R. Kaiser",
          "abstract": "Despite experiencing sexual harassment more frequently and more severely than cisgender women, transgender women survivors’/victims’ experiences of workplace sexual harassment are often omitted or ignored. Drawing from theorizing on victim prototypes and perceptions of sexual harassment, we show across six studies (total N = 2,022) that people incorrectly believe that transgender women are less likely to experience workplace sexual harassment compared to cisgender women. This effect is stronger among individuals who deny that transgender women are, in fact, women. We also show that people perceive harassment claims from transgender women who experience unwanted advances to be less credible than identical claims from cisgender women. Perceptions that transgender women are unlikely and non-credible victims of sexual harassment have important implications for understanding the erasure and neglect of transgender women survivors and the obstruction of transgender women’s civil rights.",
          "url": "https://doi.org/10.1177/01461672251368955",
          "doi": "https://doi.org/10.1177/01461672251368955",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Psychological Methods",
      "journal_short": "PM",
      "articles": [
        {
          "title": "Inferences and effect sizes for direct, indirect, and total effects in continuous-time mediation models.",
          "authors": "Ivan Jacob Agaloos Pesigan, Michael A. Russell, Sy-Miin Chow",
          "url": "https://doi.org/10.1037/met0000779",
          "doi": "https://doi.org/10.1037/met0000779",
          "filter": 0
        },
        {
          "title": "The repeated adjustment of measurement protocols method for developing high-validity text classifiers.",
          "authors": "Alex Goddard, Alex Gillespie",
          "url": "https://doi.org/10.1037/met0000787",
          "doi": "https://doi.org/10.1037/met0000787",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Psychology of Popular Media",
      "journal_short": "PPM",
      "articles": [
        {
          "title": "Can we separate the character from the creator? An exploratory study on parasocial relationships.",
          "authors": "Kristina L. Howell, Meisam Vahedi, R. Chris Fraley",
          "url": "https://doi.org/10.1037/ppm0000624",
          "doi": "https://doi.org/10.1037/ppm0000624",
          "filter": 0
        }
      ],
      "articles_hidden": []
    }
  ]
}
