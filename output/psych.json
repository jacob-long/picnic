{
  "update": "2025-05-30",
  "content": [
    {
      "journal_full": "Advances in Methods and Practices in Psychological Science",
      "journal_short": "AMPPS",
      "articles": [
        {
          "title": "An Expert Guide to Planning Experimental Tasks For Evidence-Accumulation Modeling",
          "authors": "Russell J. Boag, Reilly J. Innes, Niek Stevenson, Giwon Bahg, Jerome R. Busemeyer, Gregory E. Cox, Chris Donkin, Michael J. Frank, Guy E. Hawkins, Andrew Heathcote, Craig Hedge, Veronika Lerche, Simon D. Lilburn, Gordon D. Logan, Dora Matzke, Steven Miletić, Adam F. Osth, Thomas J. Palmeri, Per B. Sederberg, Henrik Singmann, Philip L. Smith, Tom Stafford, Mark Steyvers, Luke Strickland, Jennifer S. Trueblood, Konstantinos Tsetsos, Brandon M. Turner, Marius Usher, Leendert van Maanen, Don van Ravenzwaaij, Joachim Vandekerckhove, Andreas Voss, Emily R. Weichart, Gabriel Weindel, Corey N. White, Nathan J. Evans, Scott D. Brown, Birte U. Forstmann",
          "abstract": "Evidence-accumulation models (EAMs) are powerful tools for making sense of human and animal decision-making behavior. EAMs have generated significant theoretical advances in psychology, behavioral economics, and cognitive neuroscience and are increasingly used as a measurement tool in clinical research and other applied settings. Obtaining valid and reliable inferences from EAMs depends on knowing how to establish a close match between model assumptions and features of the task/data to which the model is applied. However, this knowledge is rarely articulated in the EAM literature, leaving beginners to rely on the private advice of mentors and colleagues and inefficient trial-and-error learning. In this article, we provide practical guidance for designing tasks appropriate for EAMs, relating experimental manipulations to EAM parameters, planning appropriate sample sizes, and preparing data and conducting an EAM analysis. Our advice is based on prior methodological studies and the our substantial collective experience with EAMs. By encouraging good task-design practices and warning of potential pitfalls, we hope to improve the quality and trustworthiness of future EAM research and applications.",
          "url": "https://doi.org/10.1177/25152459251336127",
          "doi": "https://doi.org/10.1177/25152459251336127",
          "filter": 0
        },
        {
          "title": "The Benefits of Reporting Critical-Effect-Size Values",
          "authors": "Ambra Perugini, Filippo Gambarota, Enrico Toffalini, Daniël Lakens, Massimiliano Pastore, Livio Finos, character(0), Gianmarco Altoè",
          "abstract": "Critical-effect-size values represent the smallest detectable effect that can reach statistical significance given a specific sample size, alpha level, and test statistic. It can be useful to calculate the critical effect size when designing a study and evaluate whether such effects are plausible. Reporting critical-effect-size values may be useful when the sample size has not been planned a priori, there is uncertainty about the expected sample size that can be collected, or researchers plan to analyze the data with a statistical hypothesis test. To assist researchers in calculating critical-effect-size values, we developed an R package that allows researchers to report critical-effect-size values for group comparisons, correlations, linear regressions, and meta-analyses. Reflecting on critical-effect-size values could benefit researchers during the planning phase of the study by helping them to understand the limitations of their research design. Critical-effect-size values are also useful when evaluating studies performed by other researchers when a priori power analyses were not performed, especially when nonsignificant results are observed.",
          "url": "https://doi.org/10.1177/25152459251335298",
          "doi": "https://doi.org/10.1177/25152459251335298",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Behavior Research Methods",
      "journal_short": "BRM",
      "articles": [
        {
          "title": "Cognition ratings for 8826 english words",
          "authors": "Hannah T. Corenblum, Penny M. Pexman",
          "url": "https://doi.org/10.3758/s13428-025-02663-w",
          "doi": "https://doi.org/10.3758/s13428-025-02663-w",
          "filter": 0
        },
        {
          "title": "Maximin criterion for item selection in computerized adaptive testing",
          "authors": "Jyun-Hong Chen, Hsiu-Yi Chao",
          "url": "https://doi.org/10.3758/s13428-025-02673-8",
          "doi": "https://doi.org/10.3758/s13428-025-02673-8",
          "filter": 0
        },
        {
          "title": "Talk to your data: Introducing text embedding similarity analysis (TESA) in psychological research",
          "authors": "Juul Vossen, Evy Kuijpers, Joeri Hofmans",
          "url": "https://doi.org/10.3758/s13428-025-02698-z",
          "doi": "https://doi.org/10.3758/s13428-025-02698-z",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Computers in Human Behavior",
      "journal_short": "CHB",
      "articles": [
        {
          "title": "Image-Based Sexual Abuse Profiles: Integrating Mental Health, Adversities, and Victimization to Explore Social Contexts in a Diverse Group of Young Adults",
          "authors": "Kimberly J. Mitchell, Ateret Gewirtz-Meydan, Lisa M. Jones, Heather A. Turner",
          "url": "https://doi.org/10.1016/j.chb.2025.108717",
          "doi": "https://doi.org/10.1016/j.chb.2025.108717",
          "filter": 0
        },
        {
          "title": "Introduction of the AI-Interaction Positivity Scale and its relations to satisfaction with life and trust in ChatGPT",
          "authors": "Christian Montag, Jon D. Elhai",
          "url": "https://doi.org/10.1016/j.chb.2025.108705",
          "doi": "https://doi.org/10.1016/j.chb.2025.108705",
          "filter": 0
        },
        {
          "title": "Understanding Stigmatization in Digital Sex Work: Perceptions of Camsite Members and Models",
          "authors": "Margaret Bennett-Brown, Amanda N. Gesselman, Melissa Blundell Osorio, Ellen M. Kaufman, Jessica T. Campbell",
          "url": "https://doi.org/10.1016/j.chb.2025.108719",
          "doi": "https://doi.org/10.1016/j.chb.2025.108719",
          "filter": 0
        },
        {
          "title": "Does AI and Human Advice Mitigate Punishment for Selfish Behavior? An Experiment on AI ethics From a Psychological Perspective",
          "authors": "Margarita Leib, Nils Köbis, Ivan Soraperra",
          "url": "https://doi.org/10.1016/j.chb.2025.108709",
          "doi": "https://doi.org/10.1016/j.chb.2025.108709",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Experimental Social Psychology",
      "journal_short": "JESP",
      "articles": [
        {
          "title": "Secrets lurking in the background: Investigating the underlying effects of secrets in everyday life",
          "authors": "Alisa Bedrov, Shelly L. Gable",
          "url": "https://doi.org/10.1016/j.jesp.2025.104766",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104766",
          "filter": 0
        },
        {
          "title": "Cross-cultural perceptions of racial ambiguity: Testing the universality of the ingroup overexclusion effect",
          "authors": "Mohammad S. Wiswall, Xin Tan, Jacqueline M. Chen, Sarah E. Gaither",
          "url": "https://doi.org/10.1016/j.jesp.2025.104764",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104764",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Personality and Social Psychology",
      "journal_short": "JPSP",
      "articles": [
        {
          "title": "Beliefs about what disadvantaged groups would do with power shape advantaged groups’ (un)willingness to relinquish it.",
          "authors": "Frank Jake Kachanoff, Jennifer Sheehy-Skeffington, Arnold Ho, Jennifer Richeson, Nour Kteily",
          "url": "https://doi.org/10.1037/pspi0000493",
          "doi": "https://doi.org/10.1037/pspi0000493",
          "filter": 0
        },
        {
          "title": "Punitive but discerning: Reputation can fuel ambiguously deserved punishment, but does not erode sensitivity to nuance.",
          "authors": "Jillian J. Jordan, Nour S. Kteily",
          "url": "https://doi.org/10.1037/pspa0000435",
          "doi": "https://doi.org/10.1037/pspa0000435",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Multivariate Behavioral Research",
      "journal_short": "MBR",
      "articles": [
        {
          "title": "Ideal Point or Dominance Process? Unfolding Tree Approaches to Likert Scale Data with Multi-Process Models",
          "authors": "Biao Zeng, Hongbo Wen, Minjeong Jeon",
          "url": "https://doi.org/10.1080/00273171.2025.2496505",
          "doi": "https://doi.org/10.1080/00273171.2025.2496505",
          "filter": 0
        },
        {
          "title": "Missing Data Handling via EM and Multiple Imputation in Network Analysis using Glasso and Atan Regularization",
          "authors": "Kai Jannik Nehler, Martin Schultze",
          "url": "https://doi.org/10.1080/00273171.2025.2503833",
          "doi": "https://doi.org/10.1080/00273171.2025.2503833",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Organizational Research Methods",
      "journal_short": "ORM",
      "articles": [
        {
          "title": "A Machine Learning Toolkit for Selecting Studies and Topics in Systematic Literature Reviews",
          "authors": "Andrea Simonetti, Michele Tumminello, Pasquale Massimo Picone, Anna Minà",
          "abstract": "Scholars conduct systematic literature reviews to summarize knowledge and identify gaps in understanding. Machine learning can assist researchers in carrying out these studies. This paper introduces a machine learning toolkit that employs Network Analysis and Natural Language Processing methods to extract textual features and categorize academic papers. The toolkit comprises two algorithms that enable researchers to: (a) select relevant studies for a given theme; and (b) identify the main topics within that theme. We demonstrate the effectiveness of our toolkit by analyzing three streams of literature: cobranding, coopetition, and the psychological resilience of entrepreneurs. By comparing the results obtained through our toolkit with previously published literature reviews, we highlight its advantages in enhancing transparency, coherence, and comprehensiveness in literature reviews. We also provide quantitative evidence about the toolkit's efficacy in addressing the challenges inherent in conducting a literature review, as compared with state-of-the-art Natural Language Processing methods. Finally, we discuss the critical role of researchers in implementing and overseeing a literature review aided by our toolkit.",
          "url": "https://doi.org/10.1177/10944281251341571",
          "doi": "https://doi.org/10.1177/10944281251341571",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Personality and Social Psychology Bulletin",
      "journal_short": "PSPB",
      "articles": [
        {
          "title": "How Individual Differences in Empathy Predict Moments of Empathy in Everyday Life",
          "authors": "Gregory J. Depow, Michael Inzlicht",
          "abstract": "Do trait empathy measures predict how people experience empathy in daily life? Despite considerable research on empathy, we know surprisingly little about how trait measures relate to real-world empathic experiences. In this preregistered analysis of 7,343 experience sampling surveys from a near-representative sample of 246 U.S. adults, we map the connections between validated trait empathy measures and state experiences of empathy. Each component of state empathy—including emotion sharing, perspective taking, and compassion—was significantly predicted by theoretically relevant trait measures. However, trait empathy explained limited variance in daily experiences overall, ranging from just 3% for emotion sharing to 15% for perceived empathic efficacy. Adding emotional valence as a predictor improved model fit and variance explained for most state experiences, highlighting the crucial role of context. Our findings validate trait empathy measures while revealing their limitations in predicting real-world experiences.",
          "url": "https://doi.org/10.1177/01461672251333823",
          "doi": "https://doi.org/10.1177/01461672251333823",
          "filter": 0
        },
        {
          "title": "Overconfidently Conspiratorial: Conspiracy Believers are Dispositionally Overconfident and Massively Overestimate How Much Others Agree With Them",
          "authors": "Gordon Pennycook, Jabin Binnendyk, David G. Rand",
          "abstract": "There is a pressing need to understand why people believe in conspiracies. Although past work has focused on needs and motivations, we propose an alternative driver of belief: overconfidence. Across eight studies with 4,181 U.S. adults, conspiracy believers consistently overestimated their performance on numeracy and perception tests (even after taking their actual performance into account). This relationship with overconfidence was robust in controlling for analytic thinking, the need for uniqueness, and narcissism, and it was strongest for the most fringe conspiracies. We also found that conspiracy believers—particularly overconfident ones—massively overestimated (&gt;4×) how much others agree with them: Although conspiratorial claims were believed by a majority of participants only 12% of the time, believers thought themselves to be in the majority 93% of the time. This was evident even when asked to rate agreement among counter-partisans, indicating that conspiracists are genuinely unaware that their beliefs are on the fringe.",
          "url": "https://doi.org/10.1177/01461672251338358",
          "doi": "https://doi.org/10.1177/01461672251338358",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Psychological Methods",
      "journal_short": "PM",
      "articles": [
        {
          "title": "Aggregating evidence for a central theory from diverse studies using the generalized order-restricted information criterion.",
          "authors": "R. M. Kuiper, Eli-Boaz Clapper",
          "url": "https://doi.org/10.1037/met0000755",
          "doi": "https://doi.org/10.1037/met0000755",
          "filter": 0
        },
        {
          "title": "When predictors sum to a constant: Trade-off effect analysis using a regression model based on isometric log-ratio transformation.",
          "authors": "Jieyuan Dong, Hongyun Liu",
          "url": "https://doi.org/10.1037/met0000668",
          "doi": "https://doi.org/10.1037/met0000668",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Psychological Science",
      "journal_short": "PsychSci",
      "articles": [
        {
          "title": "Are There Really People With No Inner Voice? Commentary on Nedergaard and Lupyan (2024)",
          "authors": "Andreas Lind",
          "abstract": "The idea that some people completely lack inner speech is of both scientific and popular interest. In a recent study, Nedergaard and Lupyan compared self-reporting high and low inner-speech-prevalence groups and found that participants in the low-prevalence group performed worse on a verbal working memory test and responded more slowly and less accurately during rhyme judgments. These results represent an original contribution to the study of inner speech. However, the authors go on to draw the unfounded conclusion that their findings, together with previous empirical and anecdotal data, show that some people have no inner speech at all. They have coined the term anendophasia for this trait. This commentary examines Nedergaard and Lupyan’s claim of demonstrated anendophasia; I conclude they present no compelling evidence that some individuals lack inner speech.",
          "url": "https://doi.org/10.1177/09567976251335583",
          "doi": "https://doi.org/10.1177/09567976251335583",
          "filter": 0
        },
        {
          "title": "Using the Nested Structure of Knowledge to Infer What Others Know",
          "authors": "Edgar Dubourg, Thomas Dheilly, Hugo Mercier, Olivier Morin",
          "abstract": "Humans rely on more knowledgeable individuals to acquire information. But when we are ignorant, how are we to tell who is knowledgeable? We propose that human knowledge is nested: People who know only a few things tend to know very common pieces of information, whereas rare pieces of information are known only by people who know many things, including common things. This leads to the possibility of reliably inferring knowledgeability from minimal cues. In this study ( N = 848 U.S. adults recruited online), we show that individuals can accurately gauge others’ knowledgeability on the basis of very limited information, relying on their ability to estimate the rarity of different pieces of knowledge and on the fact that knowing a rare piece of information indicates a high likelihood of knowing more information in the same theme. Even participants who are largely ignorant of a theme can infer how knowledgeable other individuals are on the basis of the possession of a single piece of knowledge.",
          "url": "https://doi.org/10.1177/09567976251339633",
          "doi": "https://doi.org/10.1177/09567976251339633",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Psychology of Music",
      "journal_short": "PsychMusic",
      "articles": [
        {
          "title": "Concertmasters’ leading-tone intonation: Do they perform as they assess?",
          "authors": "Sheng-Ying Isabella Weng, Erkki Huovinen, Sven Ahlbäck",
          "abstract": "Melodic intonation is generally considered a central expressive means in musical performance. In Western classical music, relationships between intonation in perception and performance have shown to be less straightforward than one might expect. In this study, we investigated leading-tone intonation for solo violin, as perceived and performed by six accomplished violinists. We selected excerpts from classical violin repertoire, each of which included ascending semitone intervals leading up to tonally stable tones. Each violinist performed the excerpts and participated in a listening study and a semi-structured interview. Prior recordings of the excerpts, manipulated in terms of the pitch of the leading tones, were used in the listening study to obtain information about each participant’s accepted perceptual range of leading-tone intonation. The violinists’ preferred semitone sizes were between 80 and 90 cents, on average, both in their perceptual preferences and their performance practice. This group average appeared to approximate the “standard” of leading-tone intonation that the participants consistently mentioned in their verbal protocols. However, the perceptual preferences and the performance intonation also varied both within and between individuals. Given the overall sharp standard of leading-tone intonation, even an equal-tempered leading tone might sometimes represent an expressive gesture in the violinists’ artistic practice.",
          "url": "https://doi.org/10.1177/03057356251319220",
          "doi": "https://doi.org/10.1177/03057356251319220",
          "filter": 0
        },
        {
          "title": "Editorial: Welcome by the new Editors-in-Chief",
          "authors": "Nikki Moran, Michelle Phillips",
          "url": "https://doi.org/10.1177/03057356251340891",
          "doi": "https://doi.org/10.1177/03057356251340891",
          "filter": 0
        }
      ],
      "articles_hidden": []
    }
  ]
}
