{
  "update": "2025-07-23",
  "content": [
    {
      "journal_full": "Advances in Methods and Practices in Psychological Science",
      "journal_short": "AMPPS",
      "articles": [
        {
          "title": "Bridging Traditional-Statistics and Machine-Learning Approaches in Psychology: Navigating Small Samples, Measurement Error, Nonindependent Observations, and Missing Data",
          "authors": "Rosa Lavelle-Hill, Gavin Smith, Kou Murayama",
          "abstract": "In recent years, machine learning has propagated into different aspects of psychological research, and supervised machine-learning methods have increasingly been used as a tool for predicting human behavior or psychological characteristics when there is a large number of possible predictors. However, researchers often face practical challenges when using machine-learning methods on psychological data. In this article, we identify and discuss four key challenges that often arise when applying machine learning to data collected for psychological research. The four challenge areas cover (a) limited sample size, (b) measurement error, (c) nonindependent data, and (d) missing data. Such challenges are extensively discussed in the “traditional” statistical literature but are often not explicitly addressed, or at least not to the same extent, in the applied-machine-learning community. We present how each of these challenges is dealt with first from a traditional-statistics perspective and then from a machine-learning perspective and discuss the strengths and weaknesses of these solutions by comparing the approaches. We argue that the boundary between traditional statistics and machine learning is fluid and emphasize the need for cross-disciplinary collaboration to better tackle these core challenges and improve replicability.",
          "url": "https://doi.org/10.1177/25152459251345696",
          "doi": "https://doi.org/10.1177/25152459251345696",
          "filter": 0
        },
        {
          "title": "Large Language Models for Psychological Assessment: A Comprehensive Overview",
          "authors": "Jocelyn Brickman, Mehak Gupta, Joshua R. Oltmanns",
          "abstract": "Large language models (LLMs) are extraordinary tools demonstrating potential to improve the understanding of psychological characteristics. They provide an unprecedented opportunity to supplement self-report in psychology research and practice with scalable behavioral assessment. However, they also pose unique risks and challenges. In this article, we provide an overview and guide for psychological scientists to evaluate LLMs for psychological assessment. In the first section, we briefly review the development of transformer-based LLMs and discuss their advances in natural language processing. In the second section, we describe the experimental design process, including techniques for language data collection, audio processing and transcription, text preprocessing, and model selection, and analytic matters, such as model output, model evaluation, hyperparameter tuning, model visualization, and topic modeling. At each stage, we describe options, important decisions, and resources for further in-depth learning and provide examples from different areas of psychology. In the final section, we discuss important broader ethical and implementation issues and future directions for researchers using this methodology. The reader will develop an understanding of essential ideas and an ability to navigate the process of using LLMs for psychological assessment.",
          "url": "https://doi.org/10.1177/25152459251343582",
          "doi": "https://doi.org/10.1177/25152459251343582",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Behavior Research Methods",
      "journal_short": "BRM",
      "articles": [
        {
          "title": "A novel reaction time assessment in virtual reality: Advantages over computerized tests",
          "authors": "Topaz Loushy Kay, Ella Been, Chaim G. Pick",
          "abstract": "Reaction time (RT) is a fundamental cognitive function impacting daily life and sports activities. Despite the increasing use of virtual reality (VR) for cognitive assessments, its efficacy for RT assessments remains uncertain. We aimed to develop and validate a novel RT test in VR, and to explore the potential contributions of VR technology to RT assessment. Forty-eight participants completed a computerized RT test (COM-RT) and a novel RT test in VR (VR-RT). The latter replicated the COM-RT test, assessing simple and choice RTs. Additionally, it introduced more complex conditions: reaching to touch static stimuli in known or unknown locations or moving stimuli. Correlations and differences between the tests and tasks were examined. Moderate-to-strong linear correlations were found between the tests for the simple ( r ≥ 0.642) and choice ( r ≥ 0.736) tasks, and the difference between them ( r ≥ 0.677) ( p &lt; 0.001). However, RTs were significantly longer in the VR-RT test compared with the COM-RT test ( p &lt; 0.001). Significant differences were found among the RT-VR tasks ( p &lt; 0.001): reaching to touch stimuli involved longer RTs compared with pressing a button, and RT was even longer when stimuli appeared in unexpected locations. Moving stimuli were associated with shorter RT. Additionally, movement velocity was significantly higher when reaching for dynamic versus static stimuli in known or unknown locations ( p &lt; 0.001). VR is valid for RT measurement, yet its outcomes should be interpreted within its framework rather than in comparison to computer assessments. Furthermore, VR offers additional possibilities, such as using lifelike stimuli and measuring kinematics.",
          "url": "https://doi.org/10.3758/s13428-025-02752-w",
          "doi": "https://doi.org/10.3758/s13428-025-02752-w",
          "filter": 0
        },
        {
          "title": "Developing fine-grained sense-aware lexical sophistication indices based on the CEFR levels of word senses",
          "authors": "Nan Hu, Xiaofei Lu, Renfen Hu",
          "url": "https://doi.org/10.3758/s13428-025-02741-z",
          "doi": "https://doi.org/10.3758/s13428-025-02741-z",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Computers in Human Behavior",
      "journal_short": "CHB",
      "articles": [
        {
          "title": "From icons to identity: Understanding graphicons as tools for self-representation",
          "authors": "Yoonvin Park, Daeho Lee, Jungwoo Shin, Jungmin Choi",
          "url": "https://doi.org/10.1016/j.chb.2025.108753",
          "doi": "https://doi.org/10.1016/j.chb.2025.108753",
          "filter": 0
        },
        {
          "title": "Virtual or Human Influencers as Endorsers? Behavioral and EEG Evidence of How Influencer Type Affects Purchase Intention of New Products",
          "authors": "Qingxi Yao, Yunli Liu, Bin Hu, Jia Jin",
          "url": "https://doi.org/10.1016/j.chb.2025.108754",
          "doi": "https://doi.org/10.1016/j.chb.2025.108754",
          "filter": 0
        },
        {
          "title": "Gaming together, feeling better—or feeling worse? How social video gaming impacts loneliness and depressive mood differently for boys and girls",
          "authors": "David Lacko, Filip Kyslík, David Smahel, Hana Machackova",
          "url": "https://doi.org/10.1016/j.chb.2025.108752",
          "doi": "https://doi.org/10.1016/j.chb.2025.108752",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Group Processes & Intergroup Relations",
      "journal_short": "GPIR",
      "articles": [
        {
          "title": "A case of mistaken identity: Miscategorisation of the ingroup as a historically rivalrous outgroup triggers collective narcissism",
          "authors": "Rita Guerra, Agnieszka Golec de Zavala, Kinga Bierwiaczonek, Pawel Ciesielski, Georgios Abakoumkin, Tim Wildschut, Constantine Sedikides",
          "abstract": "Collective narcissism’s links with intergroup relations, such as intergroup hostility, are well established, but less is known about the intergroup conditions that trigger it. We experimentally examined whether categorisation threat—operationalised as mistaking the ingroup for a historically rivalrous outgroup, thus undermining the ingroup’s uniqueness—heightens collective narcissism, and whether this, in turn, escalates hostility toward the pertinent outgroup through collective narcissism. Additionally, we compared collective narcissism to another form of ingroup positivity: ingroup satisfaction. We conducted four experiments ( N = 1,537) manipulating categorisation threat in two national contexts (Poland, Portugal), and carried out an internal meta-analysis. As hypothesised, the findings revealed an increase in collective narcissism, as well as a positive indirect effect of categorisation threat on outgroup hostility mediated by collective narcissism, but not by ingroup satisfaction. This research establishes categorisation threat as a robust trigger of collective narcissism.",
          "url": "https://doi.org/10.1177/13684302251345405",
          "doi": "https://doi.org/10.1177/13684302251345405",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Experimental Social Psychology",
      "journal_short": "JESP",
      "articles": [
        {
          "title": "Testing “quarantined” metarepresentational accounts of Theory of Mind: Are we biased by others' false beliefs?",
          "authors": "Steven Samuel, Robert Lurz, Daizi Davies, Harry Axtell, Sarah K. Salo",
          "url": "https://doi.org/10.1016/j.jesp.2025.104785",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104785",
          "filter": 0
        },
        {
          "title": "Face perception in context: Allocentric distance in perceptions of facial gender",
          "authors": "Spencer Dobbs, Lindsay Goolsby, Wesley Mysinger, Max Weisbuch",
          "url": "https://doi.org/10.1016/j.jesp.2025.104795",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104795",
          "filter": 0
        },
        {
          "title": "Group and personal rejection are similarly linked to extreme intergroup attitudes",
          "authors": "Luis Marcos-Vidal, Boryana Todorova, Scott Atran, Clara Pretus",
          "url": "https://doi.org/10.1016/j.jesp.2025.104788",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104788",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Personality and Social Psychology Bulletin",
      "journal_short": "PSPB",
      "articles": [
        {
          "title": "Increasing Perceived Outgroup Heterogeneity Following Exposure to Extreme Violence: An Intervention Tournament in Times of War",
          "authors": "Ilana Ushomirsky, Yossi Hasson, Renana Atia, Nitzan Attias, Meital Balmas, Kinneret Endevelt, Tamar Gur, Boaz Hameiri, Shira Hebel-Sela, Oded Adomi Leshem, Nechumi Malovicki-Yaffe, Devorah Manekin, Anat Perry, Roni Porat, Tamar Saguy, Eric Shuman, Eran Halperin",
          "abstract": "Exposure to political violence often drives individuals toward extreme attitudes and greater support for retaliatory policies, including heightened perceptions of outgroup homogeneity. In violent intergroup conflicts, such perceptions can be especially dangerous, as they may justify indiscriminate violence against the outgroup. The current research aims to address Jewish Israelis’ perceptions of Palestinians’ variability following the October 7 Hamas attack on Israel. We simultaneously conducted two intervention tournaments in which we examined the effectiveness of different interventions in increasing the perceived heterogeneity of Palestinians from the West Bank and Gaza Strip ( N = 1,564) and of Palestinian citizens of Israel ( N = 1,628). Several interventions (Outgroup empathy expression, Opinion variance, Internal criticism, Leadership-people distinction, and Moral exemplars) were found effective, suggesting that outgroup perceptions can be altered, even amid extreme violence. Implications for psychological interventions targeting outgroup variability and their implementation in the field are discussed.",
          "url": "https://doi.org/10.1177/01461672251345517",
          "doi": "https://doi.org/10.1177/01461672251345517",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Psychological Methods",
      "journal_short": "PM",
      "articles": [
        {
          "title": "Robust detection of signed outliers in multivariate data with applications to early identification of risk for autism.",
          "authors": "Jesus E. Delgado, Jed T. Elison, Nathaniel E. Helwig",
          "url": "https://doi.org/10.1037/met0000775",
          "doi": "https://doi.org/10.1037/met0000775",
          "filter": 0
        }
      ],
      "articles_hidden": []
    }
  ]
}
