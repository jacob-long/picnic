[
  {
    "discipline": "communication",
    "title": "Measuring Gaining and Holding Attention to Social Media Ads with Viewport Logging: A Validation Study Using Mobile Eye-Tracking",
    "authors": "Daniel Bruns, Julian Felix Kopka, Lennart Borgmann, Steffen Prior, Tobias Langner",
    "url": "https://doi.org/10.1080/00913367.2025.2524186",
    "doi": "https://doi.org/10.1080/00913367.2025.2524186",
    "filter": 0,
    "journal_full": "Journal of Advertising"
  },
  {
    "discipline": "communication",
    "title": "Media Exposure Diversity: An Empirical Explication",
    "authors": "Xinle Jia, Zhongdang Pan, Fangjing Tu",
    "url": "https://doi.org/10.1080/08838151.2025.2535391",
    "doi": "https://doi.org/10.1080/08838151.2025.2535391",
    "filter": 0,
    "journal_full": "Journal of Broadcasting & Electronic Media"
  },
  {
    "discipline": "communication",
    "title": "Tracking the Roots of Low News Usage on Smartphones – Do Individual Interests, Political Attitudes, and Media Consumption Habits Affect the Mobile News Use of Young Adults?",
    "authors": "Morley Weston, Daniel Vogler, Pascal Jürgens, Adrian Rauchfleisch, Mark Eisenegger",
    "url": "https://doi.org/10.1080/08838151.2025.2535389",
    "doi": "https://doi.org/10.1080/08838151.2025.2535389",
    "filter": 0,
    "journal_full": "Journal of Broadcasting & Electronic Media"
  },
  {
    "discipline": "communication",
    "title": "Consolation Strategies in Children’s News: A Comparative Content Analysis of Television and TikTok",
    "authors": "Silke Brandsen, Baldwin Van Gorp, Michaël Opgenhaffen",
    "url": "https://doi.org/10.1177/10776990251357952",
    "doi": "https://doi.org/10.1177/10776990251357952",
    "filter": 0,
    "journal_full": "Journalism & Mass Communication Quarterly",
    "abstract": "This study examined consolation strategies in children’s news on television and their remediated content on TikTok. A content analysis of 987 TikTok videos and 201 broadcasts of the Flemish children’s news program Karrewiet was conducted using a codebook developed through focus groups with children aged 8 to 12 ( N = 101) and validated via member-check interviews. Results revealed that television news relies on experts and child sources for consolation, while TikTok avoids sensational images and emphasizes the reporter’s role. In addition, the findings highlight challenges adults face in assessing potentially frightening content for children and recommend involving children in research and editorial decision-making."
  },
  {
    "discipline": "communication",
    "title": "“Truth Sandwich” To Dispel Crisis Misinformation: Exploring the Separate and Combined Impacts of Inoculation, Narratives, and Stealing Thunder on Correcting Crisis Misinformation on Social Media",
    "authors": "Young Kim, Hyunji Dana Lim",
    "url": "https://doi.org/10.1080/15205436.2025.2534979",
    "doi": "https://doi.org/10.1080/15205436.2025.2534979",
    "filter": 0,
    "journal_full": "Mass Communication and Society"
  },
  {
    "discipline": "communication",
    "title": "How Right-Wing Media, Twitter, Facebook, and YouTube Circulated Antipathy and Threat Cues About Immigrants: A Cross-Media and Cross-Platform Approach",
    "authors": "Yini Zhang, Ruixue Lian",
    "url": "https://doi.org/10.1080/15205436.2025.2529999",
    "doi": "https://doi.org/10.1080/15205436.2025.2529999",
    "filter": 0,
    "journal_full": "Mass Communication and Society"
  },
  {
    "discipline": "communication",
    "title": "Why Do You Feel That Way? Elaboration Questions and Feeling Heard in Political Talk",
    "authors": "Brittany Shaughnessy, Myiah Hutchens, Janet Coats, Ilyssa Mann, Caleb Wiegandt, Mónica Guzmán",
    "url": "https://doi.org/10.17645/mac.9977",
    "doi": "https://doi.org/10.17645/mac.9977",
    "filter": 0,
    "journal_full": "Media and Communication",
    "abstract": "Across two studies, the current work sought to understand the impact of elaboration questions in political discussion on perceptions of feeling heard and future discussion intentions. Participants were presented with a recorded video of a political conversation where we manipulated the presence and absence of elaboration questions in political conversations surrounding homelessness (Study 1) and abortion (Study 2). Results indicate the presence of elaboration questions increased perceptions of being heard and intentions to engage in discussion in the future. We also found significant indirect results where the relationship between elaboration questions and intentions to engage in future discussions was mediated by feeling heard. These findings were never moderated by whether participants agreed with the political stance taken in the conversation."
  },
  {
    "discipline": "communication",
    "title": "Mapping and Measuring Listening in Public Communication Settings",
    "authors": "Tariq Choucair",
    "url": "https://doi.org/10.17645/mac.10263",
    "doi": "https://doi.org/10.17645/mac.10263",
    "filter": 0,
    "journal_full": "Media and Communication",
    "abstract": "Scholars have made advancements in how to interpret, with detailed measures, the different characteristics and levels of distinct listening practices used by individuals when they are deliberating (Scudder, 2020, 2022). However, listening is not only a practice that occurs directly, but also a broader phenomenon that occurs across the public sphere (Bächtiger &amp;amp; Parkinson, 2019; Ercan et al., 2019). Public discourse occurs across hybrid media systems (Chadwick, 2017) in complex discursive exchanges (Maia et al., 2023) as networks of publics interact (Bruns, 2023). Such complexity imposes challenges for research to properly understand listening at a macro level. In this article, I present how to map and measure listening at this broader level. I reconstruct the discussion on listening as a normative foundation for political communication, from which we derive three key listening elements: attentiveness, openness, and responsiveness. I outline how listening is measured in direct interactions, to then explain how it can be assessed in public communication and mediated interactions, from the perspective of who listens, who is (or is not) listened to, and the actual listening acts."
  },
  {
    "discipline": "communication",
    "title": "News avoidance or curation? Explicating the psychological process in news consumption on Facebook",
    "authors": "Biying Wu-Ouyang, Shuning Lu, Hsuan-Ting Chen",
    "url": "https://doi.org/10.1177/14614448251351280",
    "doi": "https://doi.org/10.1177/14614448251351280",
    "filter": 0,
    "journal_full": "New Media & Society",
    "abstract": "This study investigates how people employ different news consumption strategies in the personalized but overloaded information environment. Specifically, we examine the psychological mechanisms of news curation and news avoidance through fear of missing out (FoMO) and news overload. An autoregressive analysis of two-wave panel data ( N = 834) shows that news use indirectly affects both news consumption strategies first through FoMO and then through news overload on Facebook. More importantly, the indirect effect occurs only for those who engage in cross-cutting discussion at high and middle but not low levels. This finding addresses a classic dilemma: despite growing concern over increased news consumption, social media users are able to strike a balance between staying informed through news curation and protecting themselves from being overloaded by news avoidance. However, these strategies can be biased because users tend to personalize their information intake after encountering disagreeing viewpoints."
  },
  {
    "discipline": "communication",
    "title": "The consequences of “The Bird is Free”: A computational analysis of aversive LGBTQIA+ tweets and engagement trends before and after Elon Musk dismantled the platform’s moderation system",
    "authors": "Gyo Hyun Koo, Josephine Lukito, Gina M Masullo, Christian Staal Bruun Overgaard, Bek Orr",
    "url": "https://doi.org/10.1177/14614448251356240",
    "doi": "https://doi.org/10.1177/14614448251356240",
    "filter": 0,
    "journal_full": "New Media & Society",
    "abstract": "This research uses Twitter discourse about LGBTQIA+ people as a case study to investigate how changes in social media platform management and policies affect conversations about marginalized communities in digital spaces. We examine Twitter discourse before and after Elon Musk’s acquisition and the immediate dismantling of content moderation efforts to identify changes in aversiveness in conversations about LGBTQIA+ people and users’ engagement with such content. Time-series intervention analyses of 6 months of Twitter data ( n = 323,440) show that tweets with toxicity, insults, and threats increased in the 3 months after Musk’s takeover, although the differences were small. The volatility of aversive content also grew over time. Post-Musk, tweets with severe toxicity and insults received more engagement than before. This research provides insight into Twitter as one representation of the shared reality of today’s cultural moment, with implications for minoritized groups and the free flow of information on social media platforms."
  },
  {
    "discipline": "communication",
    "title": "Self-Reported Exposure and Beliefs About Misinformation Across a U.S. Presidential Election Cycle: Expressive Responding and Motivated Reasoning",
    "authors": "R. Kelly Garrett, Robert M. Bond, Erik C. Nisbet",
    "url": "https://doi.org/10.1080/10584609.2025.2532584",
    "doi": "https://doi.org/10.1080/10584609.2025.2532584",
    "filter": 0,
    "journal_full": "Political Communication"
  },
  {
    "discipline": "communication",
    "title": "Deepfakes or Synthetic Media? The Effect of Euphemisms for Labeling Technology on Risk and Benefit Perceptions",
    "authors": "Adrian Rauchfleisch, Daniel Vogler, Gabriele de Seta",
    "url": "https://doi.org/10.1177/20563051251350975",
    "doi": "https://doi.org/10.1177/20563051251350975",
    "filter": 0,
    "journal_full": "Social Media + Society",
    "abstract": "The language used in public debates and in the news can influence how citizens perceive the risks and benefits of technology. While framing effects on technology perception are well understood, few studies have focused on the effects of specific terms used to describe technology. We analyze how the terms deepfake and synthetic media affect risk and benefit perceptions across application fields. Using Switzerland as a case, our manual content analysis ( n = 380 news articles) reveals a focus on risks in news coverage of deepfakes with minimal use of the term synthetic media. We then tested the effects of the terms on risk and benefit perceptions in a preregistered survey experiment (n = 736 participants). Term choice does not change perceived risks, but “synthetic media” significantly increases perceived benefits across application fields. As a theoretical contribution, we link our findings to the concept of euphemism, proposing that term choice should align with application fields to reflect the risks and benefits of technology. Overall, our study shows that the terms we use to label technology matter, especially for emerging technologies such as artificial intelligence."
  },
  {
    "discipline": "communication",
    "title": "Digital Diplomacy Followers as Indicator of Clout: Measuring the “Al-Jazeera Effect”",
    "authors": "Ilan Manor, Tal Samuel-Azran",
    "url": "https://doi.org/10.1177/19401612251345974",
    "doi": "https://doi.org/10.1177/19401612251345974",
    "filter": 0,
    "journal_full": "The International Journal of Press/Politics",
    "abstract": "The “Al-Jazeera Effect” posits that Al-Jazeera has reshaped global news flows while challenging the hegemony of Western news outlets. However, few studies to date have measured this “Effect” or offered a method for doing so. This study addressed this gap by conceptualizing news outlets’ online following as Clout and assessing Al-Jazeera’s ability to attract high-quality digital diplomacy followers on Twitter including Ministries of Foreign Affairs (MFAs) and UN Missions. Such an analysis is important as the Clout of international news outlets arises in part from their ability to impact foreign policy makers. Using a sample of 56 MFAs, and 132 UN Missions, the study analyzed Al-Jazeera’s digital diplomacy following on Twitter and compared it to that of CNN, BBC World and Reuters. Quality of digital diplomacy followers was assessed using an innovative model consisting of fifteen variables, including offline variables, online variables, and networked variables. Statistical analyses and network analyses demonstrate that Al-Jazeera attracts high-quality digital diplomacy followers, be it UN Missions of affluent states and world powers, or MFAs that are central to diplomatic networks on Twitter. The study also assessed diplomatic institutions’ engagement with Al-Jazeera Tweets, which was found to be quite low. By developing a unique model for assessing the quality of digital diplomacy followers, this study offers a method for measuring the impact of news outlets in the age of social media."
  },
  {
    "discipline": "politics",
    "title": "Balancing Precision and Retention in Experimental Design",
    "authors": "Gustavo Diaz, Erin Rossiter",
    "url": "https://doi.org/10.1017/pan.2025.10008",
    "doi": "https://doi.org/10.1017/pan.2025.10008",
    "filter": 0,
    "journal_full": "Political Analysis",
    "abstract": "In experimental social science, precise treatment effect estimation is of utmost importance, and researchers can make design choices to increase precision. Specifically, block-randomized and pre-post designs are promoted as effective means to increase precision. However, implementing these designs requires pre-treatment covariates, and collecting this information may decrease sample sizes, which in and of itself harms precision. Therefore, despite the literature’s recommendation to use block-randomized and pre-post designs, it remains unclear when to expect these designs to increase precision in applied settings. We use real-world data to demonstrate a counterintuitive result: precision gains from block-randomized or pre-post designs can withstand significant sample loss that may arise during implementation. Our findings underscore the importance of incorporating researchers’ practical concerns into existing experimental design advice."
  },
  {
    "discipline": "politics",
    "title": "Measurement issues in conflict event data: Addressing some misconceptions about what drives differences between human-coded event datasets",
    "authors": "Magnus Öberg, Mert Can Yilmaz",
    "url": "https://doi.org/10.1177/20531680251362440",
    "doi": "https://doi.org/10.1177/20531680251362440",
    "filter": 0,
    "journal_full": "Research & Politics",
    "abstract": "Clionadh Raleigh, Roudabeh Kishi, and Andrew Linke recently compared their own Armed Conflict Location and Events Dataset (ACLED) to three other conflict event datasets in Humanities &amp; Social Sciences Communications. In this article, we investigate their claims about what drives differences between the two researcher led projects the Uppsala Conflict Data Program (UCDP) and ACLED. In the process, we address some general issues that arise in event data collection, including the importance of stable definitions, how demands on sourcing varies with the type of data collected, and how strategies for dealing with uncertainty and ambiguity impact the data. Contrary to the claims made in the target article, the differences between ACLED and UCDP in the cases put forth by the authors are not primarily due to differences in sourcing or inclusion thresholds. Analyzing the same cases, we show that most of the differences are due to auxiliary coding rules, standards for source evaluation and misrepresentations of UCDP data in the original article."
  },
  {
    "discipline": "politics",
    "title": "Preferring National Elites or Local Candidates: A Conjoint Analysis of Voter Heuristics.",
    "authors": "Etienne Gagnon, Kenneth Mori McElwain, Fumi Ikeda",
    "url": "https://doi.org/10.1086/737779",
    "doi": "https://doi.org/10.1086/737779",
    "filter": 0,
    "journal_full": "The Journal of Politics"
  },
  {
    "discipline": "politics",
    "title": "Racialized Misinformation, Factual Corrections, and Prejudicial Attitudes: The Cases of Welfare and Immigration",
    "authors": "Eddy Yeung, Joseph Glasgow",
    "url": "https://doi.org/10.1086/737780",
    "doi": "https://doi.org/10.1086/737780",
    "filter": 0,
    "journal_full": "The Journal of Politics"
  },
  {
    "discipline": "public opinion",
    "title": "An Experimental Comparison of Modular and Non-Modular Approaches for Administering Surveys via Smartphone Apps",
    "authors": "Christopher Antoun, Brady T West, Xin (Rosalynn) Yang, Syed Junaid M A Zaidi, Jennifer Sinibaldi",
    "url": "https://doi.org/10.1093/jssam/smaf008",
    "doi": "https://doi.org/10.1093/jssam/smaf008",
    "filter": 0,
    "journal_full": "Journal of Survey Statistics and Methodology",
    "abstract": "Lengthy web surveys can be burdensome for respondents to complete in a single session. This study experimentally examines the effects of different app-based surveys, some of which use a modular design, on perceived burden, breakoffs, and indicators of satisficing behaviors. Participants (n = 664) were randomly assigned to one of four groups: (1) a browser-based web survey (control group), (2) an app-based survey, (3) a modular app dividing the survey into seven parts, and (4) a sequential modular app releasing modules at 48-hour intervals. Our findings indicate that administering surveys via apps can reduce the perceived burden of the survey task and improve response quality. Additionally, we find weak evidence that releasing modules individually over time can further enhance response quality, although this approach results in increased breakoffs between modules. The implications of these findings for the use of research apps and modular surveys are discussed."
  },
  {
    "discipline": "psychology",
    "title": "Bridging Traditional-Statistics and Machine-Learning Approaches in Psychology: Navigating Small Samples, Measurement Error, Nonindependent Observations, and Missing Data",
    "authors": "Rosa Lavelle-Hill, Gavin Smith, Kou Murayama",
    "url": "https://doi.org/10.1177/25152459251345696",
    "doi": "https://doi.org/10.1177/25152459251345696",
    "filter": 0,
    "journal_full": "Advances in Methods and Practices in Psychological Science",
    "abstract": "In recent years, machine learning has propagated into different aspects of psychological research, and supervised machine-learning methods have increasingly been used as a tool for predicting human behavior or psychological characteristics when there is a large number of possible predictors. However, researchers often face practical challenges when using machine-learning methods on psychological data. In this article, we identify and discuss four key challenges that often arise when applying machine learning to data collected for psychological research. The four challenge areas cover (a) limited sample size, (b) measurement error, (c) nonindependent data, and (d) missing data. Such challenges are extensively discussed in the “traditional” statistical literature but are often not explicitly addressed, or at least not to the same extent, in the applied-machine-learning community. We present how each of these challenges is dealt with first from a traditional-statistics perspective and then from a machine-learning perspective and discuss the strengths and weaknesses of these solutions by comparing the approaches. We argue that the boundary between traditional statistics and machine learning is fluid and emphasize the need for cross-disciplinary collaboration to better tackle these core challenges and improve replicability."
  },
  {
    "discipline": "psychology",
    "title": "From Embeddings to Explainability: A Tutorial on Large-Language-Model-Based Text Analysis for Behavioral Scientists",
    "authors": "Rudolf Debelak, Timo K. Koch, Matthias Aßenmacher, Clemens Stachl",
    "url": "https://doi.org/10.1177/25152459251351285",
    "doi": "https://doi.org/10.1177/25152459251351285",
    "filter": 0,
    "journal_full": "Advances in Methods and Practices in Psychological Science",
    "abstract": "Large language models (LLMs) are transforming research in psychology and the behavioral sciences by enabling advanced text analysis at scale. Their applications range from the analysis of social media posts to infer psychological traits to the automated scoring of open-ended survey responses. However, despite their potential, many behavioral scientists struggle to integrate LLMs into their research because of the complexity of text modeling. In this tutorial, we aim to provide an accessible introduction to LLM-based text analysis, focusing on the Transformer architecture. We guide researchers through the process of preparing text data, using pretrained Transformer models to generate text embeddings, fine-tuning models for specific tasks such as text classification, and applying interpretability methods, such as Shapley additive explanations and local interpretable model-agnostic explanations, to explain model predictions. By making these powerful techniques more approachable, we hope to empower behavioral scientists to leverage LLMs in their research, unlocking new opportunities for analyzing and interpreting textual data."
  },
  {
    "discipline": "psychology",
    "title": "Virtual or human influencers as endorsers? Behavioral and EEG evidence of how influencer type affects purchase intention of new products",
    "authors": "Qingxi Yao, Yunli Liu, Bin Hu, Jia Jin",
    "url": "https://doi.org/10.1016/j.chb.2025.108754",
    "doi": "https://doi.org/10.1016/j.chb.2025.108754",
    "filter": 0,
    "journal_full": "Computers in Human Behavior"
  },
  {
    "discipline": "psychology",
    "title": "“Stop the Count!”—How Reporting Partial Election Results Fuels Beliefs in Election Fraud",
    "authors": "André Vaz, Moritz Ingendahl, André Mata, Hans Alves",
    "url": "https://doi.org/10.1177/09567976251355594",
    "doi": "https://doi.org/10.1177/09567976251355594",
    "filter": 0,
    "journal_full": "Psychological Science",
    "abstract": "In seven studies, we investigated how reporting partial vote counts influences perceptions of election legitimacy. Beliefs in election fraud, as in the 2020 U.S. presidential election, may be fueled by the cumulative redundancy bias (CRB), which skews perceptions toward early leaders in partial vote counts. In line with this prediction, participants (Prolific adult participants from the United States and the United Kingdom) consistently rated early leaders more favorably and were more likely to suspect fraud when the eventual winner gained a late lead. This effect persisted across simulated elections (Studies 1–3) and real-world vote counts from the 2020 election in Georgia (Study 4). It is important to note that fraud suspicions already arose before the count was completed (Study 5) and persisted despite explanatory interventions (Study 6). Partisanship did not eliminate the CRB’s influence on fraud beliefs (Study 7). Our findings suggest that the sequential reporting of vote counts may amplify false perceptions of election fraud and could be mitigated by revising how results are communicated."
  },
  {
    "discipline": "multidisciplinary",
    "title": "Feature-based reward learning shapes human social learning strategies",
    "authors": "David Schultner, Lucas Molleman, Björn Lindström",
    "url": "https://doi.org/10.1038/s41562-025-02269-4",
    "doi": "https://doi.org/10.1038/s41562-025-02269-4",
    "filter": 0,
    "journal_full": "Nature Human Behaviour",
    "abstract": "Human adaptation depends on individuals strategically choosing whom to learn from. A mosaic of social learning strategies—such as copying majorities or successful others—has been identified. Influential theories conceive of these strategies as fixed heuristics, independent of experience. However, such accounts cannot explain the flexibility and individual variability prevalent in social learning. Here we advance a domain-general reward learning framework that provides a unifying mechanistic account of pivotal social learning strategies. We first formalize how individuals learn to associate social features (for example, others’ behaviour or success) with reward. Across six experiments ( n = 1,941), we show that people flexibly adjust their social learning in response to experienced rewards. Agent-based simulations further demonstrate how this learning process gives rise to key social learning strategies across a range of environments. Our findings suggest that people learn how to learn from others, enabling adaptive knowledge to spread dynamically throughout societies."
  },
  {
    "discipline": "multidisciplinary",
    "title": "Predicting human decisions with behavioural theories and machine learning",
    "authors": "Ori Plonsky, Reut Apel, Eyal Ert, Moshe Tennenholtz, David Bourgin, Joshua C. Peterson, Daniel Reichman, Thomas L. Griffiths, Stuart J. Russell, Even C. Carter, James F. Cavanagh, Ido Erev",
    "url": "https://doi.org/10.1038/s41562-025-02267-6",
    "doi": "https://doi.org/10.1038/s41562-025-02267-6",
    "filter": 0,
    "journal_full": "Nature Human Behaviour",
    "abstract": "Predicting human decisions under risk and uncertainty remains a fundamental challenge across disciplines. Existing models often struggle even in highly stylized tasks like choice between lotteries. Here we introduce BEAST gradient boosting (BEAST-GB), a hybrid model integrating behavioural theory (BEAST) with machine learning. We first present CPC18, a competition for predicting risky choice, in which BEAST-GB won. Then, using two large datasets, we demonstrate that BEAST-GB predicts more accurately than neural networks trained on extensive data and dozens of existing behavioural models. BEAST-GB also generalizes robustly across unseen experimental contexts, surpassing direct empirical generalization, and helps to refine and improve the behavioural theory itself. Our analyses highlight the potential of anchoring predictions on behavioural theory even in data-rich settings and even when the theory alone falters. Our results underscore how integrating machine learning with theoretical frameworks, especially those—like BEAST—designed for prediction, can improve our ability to predict and understand human behaviour."
  },
  {
    "discipline": "multidisciplinary",
    "title": "Understanding the success and failure of online political debate: Experimental evidence using large language models",
    "authors": "Tobias Heide-Jørgensen, Gregory Eady, Anne Rasmussen",
    "url": "https://doi.org/10.1126/sciadv.adv7864",
    "doi": "https://doi.org/10.1126/sciadv.adv7864",
    "filter": 0,
    "journal_full": "Science Advances",
    "abstract": "Online political debate is frequently lamented for being toxic, partisan, and counterproductive. However, we know little about how core elements of political debate (justification, tone, willingness to compromise, and partisanship) affect its quality. Using text-based treatments experimentally manipulated with a large language model, we test how these elements causally affect the quality of open-text responses about issues important to the US and UK public. We find substantial evidence that differences in justification, tone, and willingness to compromise, but not partisanship, affect the quality of subsequent discourse. Combined, these elements increase the probability of high-quality responses by roughly 1.6 to 2 times and substantially increase openness to alternative viewpoints. Despite the ability to bring about substantial changes in discourse quality, we find no evidence of changes in political attitudes themselves. Our findings demonstrate how adapting approaches to online debate can foster healthy democratic interactions but have less influence on changing minds."
  }
]
