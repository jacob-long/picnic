{
  "update": "2025-08-27",
  "content": [
    {
      "journal_full": "Journal of Elections, Public Opinion and Parties",
      "journal_short": "JEPOP",
      "articles": [
        {
          "title": "Exposure to one-sided messaging and belief in voter fraud: the curious case of the US 2020 presidential election",
          "authors": "Daniel M. Gomez, Matthew David Jenkins",
          "url": "https://doi.org/10.1080/17457289.2025.2514203",
          "doi": "https://doi.org/10.1080/17457289.2025.2514203",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Politics, Groups, and Identities",
      "journal_short": "PGI",
      "articles": [
        {
          "title": "Negotiating the boundaries of farmerhood: class, race, and identity in the new rural South Africa",
          "authors": "Alex Dyzenhaus, Carolyn E. Holmes",
          "url": "https://doi.org/10.1080/21565503.2025.2539502",
          "doi": "https://doi.org/10.1080/21565503.2025.2539502",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Social Science Computer Review",
      "journal_short": "SSCR",
      "articles": [
        {
          "title": "Learning to Live with COVID-19: Informative Fictions of TikTok Misinformation and Multimodal Video Analysis",
          "authors": "Zituo Wang, Lingtong Hu, Jiayi Zhu, Donggyu Kim, Xiaojing Bo",
          "abstract": "The spread of misinformation has historically been attributed to emotions, thinking styles, biases, and predispositions, but only a few studies have explored the conditions influencing its prevalence. The Theory of Informative Fictions (TIF) addresses this gap by presenting propositions that predict the conditions under which misinformation is tolerated and promoted. Building on the literature on TIF and deep learning, we uncover how property messages and character messages differ in veracity and explore the relationship between visual misinformation and user engagement. By constructing a short video dataset Tikcron ( N = 42,201) and a multimodal video analysis framework KILL, we classify TikTok videos as misinformation or not, and property messages or character messages. Our results indicate that character messages are more likely to convey misinformation than property messages, and character messages with misinformation are more likely to get tolerated and promoted by social media users than property messages with misinformation. This study extends the current methodological advancement of image-as-data to misinformation videos and proposes a multimodal video analysis framework to develop communication-centered theories. The broader practical implications of this study on the detection, countering, and governance of visual misinformation are also discussed.",
          "url": "https://doi.org/10.1177/08944393251366232",
          "doi": "https://doi.org/10.1177/08944393251366232",
          "filter": 0
        },
        {
          "title": "The Sociology of Technical Choices in Predictive AI",
          "authors": "Michael Zanger-Tishler, Simone Zhang",
          "abstract": "Predictive AI models increasingly guide high-stakes institutional decisions across domains from criminal justice to education to finance. A rich body of interdisciplinary scholarship has emerged examining the technical choices made during the creation of these systems. This article synthesizes this emerging literature for a sociology audience, mapping key decision points in predictive AI development where diverse forms of sociological expertise can contribute meaningful insights. From how social problems are translated into prediction problems, to how models are developed and evaluated, to how their outputs are presented to decision-makers and subjects, we outline various ways sociologists across subfields and methodological specialities can engage with the technical aspects of predictive AI. We discuss how this engagement can strengthen theoretical frameworks, expose embedded policy choices, and bridge the gap between model development and use. By examining technical choices and design processes, this agenda can deepen understanding of the reciprocal relationship between AI and society while advancing broader sociological theory and research.",
          "url": "https://doi.org/10.1177/08944393251367045",
          "doi": "https://doi.org/10.1177/08944393251367045",
          "filter": 0
        }
      ],
      "articles_hidden": []
    }
  ]
}
