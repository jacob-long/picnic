{
  "update": "2024-11-07",
  "content": [
    {
      "journal_full": "Journal of Elections, Public Opinion and Parties",
      "journal_short": "JEPOP",
      "articles": [
        {
          "title": "Inconsistency of Americans’ opinions on free speech: evidence from three survey experiments",
          "authors": "Kirill Zhirkov, Rachel Smilan-Goldstein",
          "url": "http://dx.doi.org/10.1080/17457289.2024.2421572",
          "doi": "10.1080/17457289.2024.2421572",
          "filter": 0
        },
        {
          "title": "Candidate shortages and the electoral consequences for radical right-wing parties: insights from Sweden",
          "authors": "Zeth Isaksson",
          "url": "http://dx.doi.org/10.1080/17457289.2024.2421566",
          "doi": "10.1080/17457289.2024.2421566",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Public Opinion Quarterly",
      "journal_short": "POQ",
      "articles": [
        {
          "title": "The Long Shadow of the Big Lie: How Beliefs about the Legitimacy of the 2020 Election Spill Over onto Future Elections",
          "authors": "Matthew Levendusky, Shawn Patterson, Michele Margolis, Yotam Ophir, Dror Walter, Kathleen Hall Jamieson",
          "abstract": "Has the “big lie”—the false claim that the 2020 election was stolen from Donald Trump—shaped citizens’ views of the legitimacy of other US elections? We argue that it has. Those who believe Trump’s claim, whom we call election skeptics, lack confidence in elections for two interrelated reasons. First, because they think 2020 was inaccurately and unfairly conducted, they think that other elections will suffer a similar fate, and hence think these elections are illegitimate even before any votes are cast. Second, while most voters think elections are less legitimate when their preferred candidate loses, this effect will be especially large for election skeptics, because voter fraud gives them a mechanism to explain their candidate’s loss. Using an original panel dataset spanning the 2020 and 2022 elections, we show strong support for these hypotheses. This has important implications for our elections, and their legitimacy, moving forward.",
          "url": "http://dx.doi.org/10.1093/poq/nfae047",
          "doi": "10.1093/poq/nfae047",
          "filter": 0
        },
        {
          "title": "AAPOR Presidential Address Focusing Our Vision: Drawing on AAPOR’s New Strategic Plan to Shape Our Future",
          "authors": "Jennifer Agiesta",
          "url": "http://dx.doi.org/10.1093/poq/nfae046",
          "doi": "10.1093/poq/nfae046",
          "filter": 0
        },
        {
          "title": "Ordering Effects versus Cognitive Burden: How Should We Structure Attributes in Conjoint Experiments?",
          "authors": "Lukas Rudolph, Markus Freitag, Paul W Thurner",
          "abstract": "Conjoint experiments offer a flexible way to elicit population preferences on complex decision tasks. We investigate whether we can improve respondents’ survey experience and, ultimately, choice quality by departing from the current recommendation of completely randomized conjoint attribute ordering. Such random ordering guarantees that potential bias from attribute order cancels out on average. However, in situations with many attributes, this may unnecessarily increase cognitive burden, as attributes belonging together conceptually are presented scattered across the choice table. Hence, we study experimentally whether purposeful ordering (“theoretically important” attributes first) or block randomized ordering (attributes belonging to the same theoretical concept displayed in randomized bundles) affects survey experience, response time, and choice itself, as compared to completely randomized ordering. Drawing on a complex preregistered choice design with nine attributes (N = 6,617), we find that ordering type affects neither self-reported survey experience, choice task timing, nor attribute weighting. Potentially, block randomization reduces cognitive burden for some subgroups. To our knowledge, we thereby provide the first systematic empirical evidence that ordering effects are likely of low relevance in conjoint choice experiments and that the trade-off between cognitive burden and ordering effects is minimal from the perspective of respondents, at least for our substantive application.",
          "url": "http://dx.doi.org/10.1093/poq/nfae038",
          "doi": "10.1093/poq/nfae038",
          "filter": 0
        }
      ],
      "articles_hidden": []
    }
  ]
}
