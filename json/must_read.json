[
  {
    "discipline": "communication",
    "title": "Eye-Tracking Research in Advertising Scholarship: A Review and Practical Guide",
    "authors": "Claire M. Segijn",
    "url": "https://doi.org/10.1080/00913367.2025.2528215",
    "doi": "https://doi.org/10.1080/00913367.2025.2528215",
    "filter": 0,
    "journal_full": "Journal of Advertising"
  },
  {
    "discipline": "communication",
    "title": "How cognitive elaboration fosters knowledge acquisition on social media—a field experiment",
    "authors": "Luna T Frauhammer, Jana H Dreston",
    "abstract": "Social media technologies have been criticized as ineffective sources of information because users seem to increase their subjective but not their objective knowledge. While different factors such as multitasking have been brought up as explanations, direct and fair comparisons of learning outcomes between social and traditional news media are missing. This two-wave field experiment (N1 = 902, N2 = 663) shows that whereas participants receiving information on social media did learn less than participants receiving the same information through an email newsletter, this difference disappeared when cognitive elaboration on social media was triggered through elaboration questions. Correlational analyses further suggest that multitasking is one factor which hinders successful knowledge acquisition on social media. Our findings suggest that learning through social media is possible if social media contents invite cognitively elaborate processing.",
    "url": "https://doi.org/10.1093/jcmc/zmaf014",
    "doi": "https://doi.org/10.1093/jcmc/zmaf014",
    "filter": 0,
    "journal_full": "Journal of Computer-Mediated Communication"
  },
  {
    "discipline": "communication",
    "title": "Social (media) psychology of the “news-finds-me” perception: habits, mindsets, and beliefs",
    "authors": "Scott W Campbell, Ian Hawkins",
    "abstract": "Unintended encounters with news on social media can foster a reliance on incidental news exposure and the perception that “news finds me.” Because the “news-finds-me” (NFM) perception has negative consequences for informed and engaged citizenship, explaining it has become a priority in recent years. This two-wave survey of adults in the USA incorporates scholarship on social media habits and social media mindsets for an expanded view of the antecedent psychological conditions of the “news-finds-me” perception. Path analyses indicate habitual use of social media to have direct effects and core beliefs about social media and algorithmic control to have indirect effects through habitual use. These patterns hold for two of the three sub-dimensions of the NFM perception, indicating habit and mindset to be fruitful theoretical directions for future research.",
    "url": "https://doi.org/10.1093/jcmc/zmaf010",
    "doi": "https://doi.org/10.1093/jcmc/zmaf010",
    "filter": 0,
    "journal_full": "Journal of Computer-Mediated Communication"
  },
  {
    "discipline": "communication",
    "title": "Defining and Validating News Skepticism: Distinctions from News Trust and Cynicism, and Links to News Literacy and Misinformation Belief",
    "authors": "Gyo Hyun Koo, Tamar Wilner, Cameron McCann",
    "url": "https://doi.org/10.1080/15205436.2025.2534983",
    "doi": "https://doi.org/10.1080/15205436.2025.2534983",
    "filter": 0,
    "journal_full": "Mass Communication and Society"
  },
  {
    "discipline": "communication",
    "title": "Illuminating the invisible: Development and psychometric test of a multi-dimensional measure of consistent online lurking (COOL)",
    "authors": "Alexandra R Stankus, Archana Krishnan",
    "abstract": "Online lurking is a common behavior but defining it and understanding its motivations is complex. Various definitions and measurements for online lurking have been employed but have often suggested “lurking” to be conflated with other behaviors. This study developed and tested a scale to measure consistent online lurking (COOL), addressing the need for a clear conceptualization and measurement of this behavior. Exploratory factor analysis explicated two dimensions of online lurking – online invisibility and preference for content consumption, and confirmatory factor analysis confirmed the two-factor structure. The resulting scale demonstrated good reliability across two samples. The study differentiates consistent lurking from information-seeking and contextual factors, focusing on individuals who tend to lurk across platforms. This conceptualization provides a theoretical contribution by illuminating a subset of online users who are often underrepresented in research but are integral to online communities despite their invisibility.",
    "url": "https://doi.org/10.1177/14614448251358488",
    "doi": "https://doi.org/10.1177/14614448251358488",
    "filter": 0,
    "journal_full": "New Media & Society"
  },
  {
    "discipline": "communication",
    "title": "Attributing coordinated social media manipulation: A theoretical model and typology",
    "authors": "Daniel Thiele, Miriam Milzner, Annett Heft, Baoning Gong, Barbara Pfetsch",
    "abstract": "Social media are key arenas for public opinion formation, but are susceptible to coordinated social media manipulation (CSMM), that is, the orchestrated activity of multiple accounts to increase content visibility and deceive audiences. Despite advances in detecting and characterizing CSMM, the attribution problem—identifying the principals behind CSMM campaigns—has received little scholarly attention. In this article, we address this gap by synthesizing existing research and developing a theoretical model for understanding CSMM. We propose a consolidated definition of CSMM, identify its key observable and hidden characteristics, and present a rational choice model for inferring principals’ strategic decisions from campaign features. In addition, we present a typology of CSMM campaigns, linking variations in scale, elaborateness, and disguise to principals’ resources, stakes, and influence strategies. Our contribution provides researchers with conceptual and heuristic tools for attribution and invites interdisciplinary and comparative research on CSMM campaigns.",
    "url": "https://doi.org/10.1177/14614448251350100",
    "doi": "https://doi.org/10.1177/14614448251350100",
    "filter": 0,
    "journal_full": "New Media & Society"
  },
  {
    "discipline": "communication",
    "title": "Do Politicians’ Genders Influence Voter Persuasion?",
    "authors": "Hirofumi Miwa, Ikuma Ogura",
    "url": "https://doi.org/10.1080/10584609.2025.2519159",
    "doi": "https://doi.org/10.1080/10584609.2025.2519159",
    "filter": 0,
    "journal_full": "Political Communication"
  },
  {
    "discipline": "communication",
    "title": "The Moral Foundations of Populist Communication: A Semantic Network Analysis of Political Parties’ Social Media Discourse in a Multiparty System",
    "authors": "Anna Wickenkamp, Frederic R. Hopp, Michael Hameleers, Linda Bos",
    "abstract": "Social media have transformed political campaigning by enabling direct interaction between politicians and voters, becoming a key tool for shaping public opinion. Moral language is pivotal in this dynamic as it captures attention in an overly information-saturated social media environment and wields significant influence over political opinions. Populists thrive on social media by fostering distrust in elites, using emotional language, and reducing complex issues to simple “us vs. them” binaries. We argue these factors are rooted in moral underpinnings, which may play a significant role in the appeal of populist parties and have thus far received limited scholarly attention. Consequently, this paper addresses the research question: To what extent, and in what ways, do populist parties exhibit a distinct moral-rhetorical profile on social media that sets them apart from mainstream politicians? Using Moral Foundations Theory, natural language processing, and a computational semantic network approach, we analyzed 11,205 social media posts from Dutch political parties and leaders during the 2023 Dutch election campaign across X, Facebook, and Instagram. Our findings reveal that populist parties emphasize Care and Authority over other moral foundations, while mainstream parties exhibit a different moral foundation distribution. These results align with the part of populist communication logic that frames populist actors as defenders against corrupt elites and external threats, as well as representatives of the people’s demand for sovereignty. Moreover, we found populist parties exhibit less internal consistency in their moral rhetoric across platforms than mainstream parties, suggesting a potentially higher adeptness at tailoring messages to different platforms and their affordances.",
    "url": "https://doi.org/10.1177/20563051251357271",
    "doi": "https://doi.org/10.1177/20563051251357271",
    "filter": 0,
    "journal_full": "Social Media + Society"
  },
  {
    "discipline": "politics",
    "title": "Re-Stigmatizing the Radical Right: A One-Way Street?",
    "authors": "Laia Balcells, Sergi Martínez, Vicente Valentim, Ethan vanderWilden",
    "abstract": "Radical right behavior and support for radical right parties have increased across many countries in recent decades. A growing body of research has argued that, similar to the spread of other extremist behaviors, this is due to an erosion of political norms. This suggests that re-stigmatizing radical right parties might be an effective way of countering their growth. We use a survey experiment in Spain that compares the effectiveness of three theory-driven interventions aimed at increasing political stigma against a radical right party. Contrary to expectations, we fail to validate the efficacy of vignette-based attempts at stigmatization, instead identifying some backlash effects. Methodologically, our findings underscore the importance of validating treatments, as we show that simple attempts at re-stigmatization can produce null or opposing effects to their intended purpose. Theoretically, our results support the idea that normalization is a “one-way street,” in that re-stigmatizing parties is difficult after a party has become normalized.",
    "url": "https://doi.org/10.1017/xps.2025.10007",
    "doi": "https://doi.org/10.1017/xps.2025.10007",
    "filter": 0,
    "journal_full": "Journal of Experimental Political Science"
  },
  {
    "discipline": "politics",
    "title": "The state of populism: Introducing the 2023 wave of the Populism and political parties expert survey",
    "authors": "Andrej Zaslove, Robert A Huber, Maurits J. Meijers",
    "abstract": "To understand the evolution of party-based populism, reliable and valid measurement is essential. This article presents the second wave of the Populism and Political Parties Expert Survey, capturing populism with a continuous, five-item multidimensional latent construct in 312 political parties across 31 European countries in 2023. We validate the approach through Exploratory Factor Analysis (EFA), Confirmatory Factor Analysis (CFA) and Item Response Theory (IRT). The IRT findings confirm the discriminatory power of the five items, while CFA results establish strict measurement invariance from 2018 to 2023, allowing for cross-temporal comparisons. Substantively, we show that radical right parties remain the most populist, followed by the radical left, with both nativism and left-wing economic stances as robust predictors of populism. Overall, average populism levels declined from 2018 to 2023, largely due to decreases among parties with weaker nativist and authoritarian tendencies.",
    "url": "https://doi.org/10.1177/13540688251361813",
    "doi": "https://doi.org/10.1177/13540688251361813",
    "filter": 0,
    "journal_full": "Party Politics"
  },
  {
    "discipline": "politics",
    "title": "Bin-Conditional Conformal Prediction of Fatalities from Armed Conflict",
    "authors": "David Randahl, Jonathan P. Williams, Håvard Hegre",
    "abstract": "Forecasting of armed conflicts is a critical area of research with the potential to save lives and mitigate suffering. While existing forecasting models offer valuable point predictions, they often lack individual-level uncertainty estimates, limiting their usefulness for decision-making. Several approaches exist to estimate uncertainty, such as parametric and Bayesian prediction intervals, bootstrapping, quantile regression, but these methods often rely on restrictive assumptions, struggle to provide well-calibrated intervals across the full range of outcomes, or are computationally intensive. Conformal prediction offers a model-agnostic alternative that guarantees a user-specified level of coverage but typically provides only marginal coverage, potentially resulting in non-uniform coverage across different regions of the outcome space. In this article, we introduce a novel extension called bin-conditional conformal prediction (BCCP), which enhances standard conformal prediction (SCP) by ensuring consistent coverage rates across user-defined subsets (bins) of the outcome variable. We apply BCCP to simulated data as well as the forecasting of fatalities from armed conflicts, and demonstrate that it provides well-calibrated uncertainty estimates across various ranges of the outcome. Compared to SCP, BCCP offers improved local coverage, though this comes at the cost of slightly wider prediction intervals.",
    "url": "https://doi.org/10.1017/pan.2025.10010",
    "doi": "https://doi.org/10.1017/pan.2025.10010",
    "filter": 0,
    "journal_full": "Political Analysis"
  },
  {
    "discipline": "politics",
    "title": "Detecting Formatted Text: Data Collection Using Computer Vision",
    "authors": "Jonathan Colner",
    "abstract": "Research in political science has begun to explore how to use large language and object detection models to analyze text and visual data. However, few studies have explored how to use these tools for data extraction. Instead, researchers interested in extracting text from poorly formatted sources typically rely on optical character recognition and regular expressions or extract each item by hand. This letter describes a workflow process for structured text extraction using free models and software. I discuss the type of data best suited to this method, its usefulness within political science, and the steps required to convert the text into a usable dataset. Finally, I demonstrate the method by extracting agenda items from city council meeting minutes. I find the method can accurately extract subsections of text from a document and requires only a few hand labeled documents to adequately train.",
    "url": "https://doi.org/10.1017/pan.2025.10006",
    "doi": "https://doi.org/10.1017/pan.2025.10006",
    "filter": 0,
    "journal_full": "Political Analysis"
  },
  {
    "discipline": "politics",
    "title": "A Waste of Time? Partisan Deliberative Bias as a Barrier to Political Crosstalk",
    "authors": "Bryan McLaughlin, Nathaniel Geiger, Pedro H. P. Rocha",
    "abstract": "Americans are increasingly unwilling to talk about politics with out-partisans. One potential barrier to such cross-cutting partisan conversations may be partisans’ tendency to stereotype out-partisans as lacking the deliberative traits necessary to have a productive conversation (i.e., partisan deliberative bias ). Here, three studies examine the presence of partisan deliberative bias, its relationship to cross-cutting political talk, and potential pathways to reducing partisan deliberative bias. Study 1 (two-wave panel; Wave-2 N = 695) provides evidence that partisans perceive out-partisans possess less deliberative traits than in-partisans and these perceptions are related to reduced cross-cutting political talk (at Time 2). Study 2 (experimental; N = 417) provides evidence that exposing individuals to more examples of out-partisans who display deliberative traits (vs. anti-deliberative traits) leads to increased perceptions that out-partisans possess deliberative traits, which is associated with greater willingness to engage in a political conversation. Study 3 (experimental; N = 825) provides evidence that a deliberative bias-correcting intervention can reduce stereotypes about out-party members’ deliberative traits. Further, findings from an alternative model that includes in-group favoritism suggest that perceptions of deliberative traits are significantly related to cross-cutting political talk even when accounting for affective polarization. Findings across all three studies are similar for Republican and Democratic participants. Taken holistically, these results highlight the prevalence of partisan deliberative bias, suggest that such bias reduces cross-cutting conversations, and provide preliminary evidence for the effectiveness of interventions to address this bias.",
    "url": "https://doi.org/10.1007/s11109-025-10068-w",
    "doi": "https://doi.org/10.1007/s11109-025-10068-w",
    "filter": 0,
    "journal_full": "Political Behavior"
  },
  {
    "discipline": "politics",
    "title": "Out‐party, out of luck: Partisan biases in public support for due process in corruption investigations",
    "authors": "Pedro C. Magalhães, Luís de Sousa, Nuno Garoupa, Rui Costa‐Lopes",
    "abstract": "This study examines how public support for due process in corruption investigations is affected by partisan biases. Using a survey experiment conducted with a representative sample of Portuguese voters, it finds that voters' support for legally enshrined due process rights is conditional on their partisan alignment with the corruption suspects. Specifically, respondents exhibit greater support for due process protections for in‐party than for out‐party suspects, with out‐party derogation prevailing. By focusing on public attitudes towards legal fairness and horizontal accountability, these results expand our understanding of the role of partisan loyalties in accountability for corruption beyond their better‐known role in electoral processes.",
    "url": "https://doi.org/10.1111/pops.70063",
    "doi": "https://doi.org/10.1111/pops.70063",
    "filter": 0,
    "journal_full": "Political Psychology"
  },
  {
    "discipline": "politics",
    "title": "Large Language Models Are Democracy Coders with Attitudes",
    "authors": "Nils B. Weidmann, Mats Faulborn, David García",
    "abstract": "Current political developments worldwide illustrate that research on democratic backsliding is as important as ever. A recent exchange in Political Science &amp; Politics (February 2024) highlighted again that the measurement of democracy remains a challenge. With many democracy indicators consisting of subjective assessments rather than factual observations, trends in democracy over time could be due to human biases in the coding of these indicators rather than empirical facts. This article leverages two cutting-edge Large Language Models (LLMs) for the coding of democracy indicators from the V-Dem project. With access to huge amounts of information, these models may be able to rate the many “soft” characteristics of regimes at substantially lower costs. Whereas LLM-generated codings largely align with expert coders for many countries, we show that when these models deviate from human assessments, they do so in different but consistent ways. Some LLMs are too pessimistic and others consistently overestimate the democratic quality of these countries. Although the combination of the two LLM codings can alleviate this concern, we conclude that it is difficult to replace human coders with LLMs because the extent and direction of these attitudes is not known a priori.",
    "url": "https://doi.org/10.1017/s1049096525101248",
    "doi": "https://doi.org/10.1017/s1049096525101248",
    "filter": 0,
    "journal_full": "PS: Political Science & Politics"
  },
  {
    "discipline": "psychology",
    "title": "Side Effects of Experience-Sampling Protocols: A Systematic Analysis of How They Affect Data Quality, Data Quantity, and Bias in Study Results",
    "authors": "Thomas Reiter, Sophia Sakel, Julian Scharbert, Julian ter Horst, Maarten van Zalk, Mitja Back, Markus Bühner, Ramona Schoedel",
    "abstract": "In studies using the increasingly popular experience-sampling method (ESM), design decisions are often guided by theoretical or practical considerations. Yet limited empirical evidence exists on how these choices affect data quantity (e.g., response probabilities), data quality (e.g., response latency), and potential biases in study outcomes (e.g., characteristics of study variables). In a preregistered, 4-week study ( N = 395), we experimentally manipulated two key ESM protocol characteristics for sending ESM surveys: timing (fixed vs. varying times) and contingency (directly vs. indirectly after unlocking the smartphone). We evaluated the ESM protocols resulting from the combination of these two characteristics regarding different criteria: As hypothesized for contingency, indirect protocols resulted in higher response probabilities (increased data quantity). But they also led to higher response latencies (reduced data quality). Contrary to our expectations, the combined effect of contingency and timing did not significantly influence response probability. We also did not observe other effects of timing or contingency on data quality. In exploratory follow-up analyses, we discovered that timing significantly affected response probability and smartphone-usage behaviors, as measured by screen logs; however, these effects were likely attributable to time-of-day effects. Self-reported states showed no differences based on the chosen ESM protocol, and similar trends were found when correlating primary outcomes with external criteria, such as trait affect and well-being. Based on the study’s findings, we discuss the trade-offs that researchers should consider when choosing their ESM protocols to optimize data quantity, data quality, and biases in study outcomes.",
    "url": "https://doi.org/10.1177/25152459251347274",
    "doi": "https://doi.org/10.1177/25152459251347274",
    "filter": 0,
    "journal_full": "Advances in Methods and Practices in Psychological Science"
  },
  {
    "discipline": "psychology",
    "title": "When is enough enough? Empirical guidelines to determine participant sample size for scene viewing studies",
    "authors": "Alex J. Hoogerbrugge, Ignace T. C. Hooge, Roy S. Hessels, Christoph Strauch",
    "abstract": "Eye tracking is widely used to study where spatial attention is allocated across stimuli. However, determining a sufficient and efficient number of participants for such studies remains a challenge. While clear guidelines have been established for many classical statistical tests, no straightforward participant sample size guidelines exist for the comparison of gaze distribution maps and area-of-interest analyses – two of the most prominent analyses in scene viewing studies. Just how many participants should be included for reliable and reproducible gaze estimations? We here utilized gaze data to a single static image, viewed by 1248 individuals (dataset 1), and gaze data to 200+ images, viewed by 84 participants each (dataset 2). Researchers can assess which of these datasets and analysis types most resemble their setup and determine their sample size accordingly. Although we cannot provide a one-size-fits-all sample size recommendation, we show progressively diminishing returns for a range of sample sizes and for two typical study types. For example, when using Normalized Saliency Score as a metric of distribution map similarity, a 5% relative increase requires increases in sample size from 13 $$\\rightarrow $$ → 20 $$\\rightarrow $$ → 34 participants (based on dataset 1) or from 10 $$\\rightarrow $$ → 16 $$\\rightarrow $$ → 32 participants (based on dataset 2). Alternatively, when analyzing the number of visits to certain areas of interest, a 25% decrease in outcome variance requires increases in sample size from 13 $$\\rightarrow $$ → 24 $$\\rightarrow $$ → 44. We provide easy-to-use guidelines and reference tables to determine scene viewing participant sample size for academics and industry professionals alike.",
    "url": "https://doi.org/10.3758/s13428-025-02754-8",
    "doi": "https://doi.org/10.3758/s13428-025-02754-8",
    "filter": 0,
    "journal_full": "Behavior Research Methods"
  },
  {
    "discipline": "psychology",
    "title": "Bayesian sample size determination for longitudinal intervention studies with linear and log-linear growth",
    "authors": "Ulrich Lösener, Mirjam Moerbeek",
    "abstract": "A priori sample size determination (SSD) is essential for designing cost-efficient trials and in avoiding underpowered studies. In addition, reporting a solid justification for a certain sample size is required by most ethics committees and many funding agencies. Often, SSD is based on null hypothesis significance testing (NHST), an approach that has received severe criticism in the past decades. As an alternative, Bayesian hypothesis evaluation using Bayes factors has been developed. Bayes factors quantify the relative support in the data for a pair of competing hypotheses without suffering from some of the drawbacks of NHST. SSD for Bayesian hypothesis testing relies on simulations and has only been studied recently. Available software for this is limited to simple models such as ANOVA and the t  test, in which observations are assumed to be independent from each other. However, this assumption is rendered untenable in longitudinal experiments where observations are nested within individuals. In that case, a multilevel model should be used. This paper provides researchers with a valuable tool for performing SSD for multilevel models with longitudinal data in a Bayesian framework, along with the necessary theoretical background and concrete empirical examples. The open-source R function that enables researchers to tailor the simulation to their trial at hand can be found on the GitHub page of the first author.",
    "url": "https://doi.org/10.3758/s13428-025-02749-5",
    "doi": "https://doi.org/10.3758/s13428-025-02749-5",
    "filter": 0,
    "journal_full": "Behavior Research Methods"
  },
  {
    "discipline": "psychology",
    "title": "An explainable artificial intelligence handbook for psychologists: Methods, opportunities, and challenges.",
    "authors": "Rosa Lavelle-Hill, Gavin Smith, Hannah Deininger, Kou Murayama",
    "url": "https://doi.org/10.1037/met0000772",
    "doi": "https://doi.org/10.1037/met0000772",
    "filter": 0,
    "journal_full": "Psychological Methods"
  },
  {
    "discipline": "sociology",
    "title": "Online Nonprobability Samples",
    "authors": "Jeremy Freese, Olivia Jin",
    "abstract": "Online nonprobability samples provide social scientists with opportunities to conduct surveys and experiments on large, diverse samples at modest prices. Researchers may find bewildering the options offered by the many commercial entities that provide research participants, and our review seeks to orient researchers to key issues about their use. We discuss principles and evidence regarding estimates from nonprobability samples versus those from probability samples. We also describe methods for addressing certain types of problem participants that one encounters in these samples: professional respondents, participants who are inattentive or have low linguistic competence, and bogus participants (increasingly in the form of bots). We urge researchers not to take data quality for granted, not to rely on indirect information to vouch for data quality, and to proactively build methods that allow for the evaluation of data quality into their instruments.",
    "url": "https://doi.org/10.1146/annurev-soc-090524-043117",
    "doi": "https://doi.org/10.1146/annurev-soc-090524-043117",
    "filter": 0,
    "journal_full": "Annual Review of Sociology"
  },
  {
    "discipline": "sociology",
    "title": "Survey Experiments in Sociology",
    "authors": "Ariela Schachter, Katherine Weisshaar",
    "abstract": "Survey experiments are an underutilized but powerful tool for sociologists interested in studying causal research questions. Survey experiments can yield insights into the breadth of causal relationships, by studying treatment effects in population samples or across subgroups, and can yield a deeper understanding of causal processes that are not readily observed with other social science methodologies. In this article, we begin by considering the conditions under which survey experiments are a uniquely useful method and highlight emblematic examples of recent sociological research. We then discuss some of the challenges and limitations of survey experiments as a research method before offering a brief practical guide to sociologists interested in conducting survey experiments. We conclude with reflections on the future of survey experimental research in sociology.",
    "url": "https://doi.org/10.1146/annurev-soc-083024-070113",
    "doi": "https://doi.org/10.1146/annurev-soc-083024-070113",
    "filter": 0,
    "journal_full": "Annual Review of Sociology"
  },
  {
    "discipline": "sociology",
    "title": "Meaning in Hyperspace: Word Embeddings as Tools for Cultural Measurement",
    "authors": "Andrei Boutyline, Alina Arseniev-Koehler",
    "abstract": "Word embeddings are language models that represent words as positions in an abstract many-dimensional meaning space. Despite a growing range of applications demonstrating their utility for sociology, there is little conceptual clarity regarding what exactly embeddings measure and whether this matches what we need them to measure. Here, we fill this theoretical gap by clarifying how cultural meaning can be understood in spatial terms. We argue that embeddings operationalize context spaces, where words’ positions can reflect any regularity in usage. We then examine sociologists' embeddings-based measurements to argue that most sociologists are instead implicitly interested in capturing concept spaces, where positions strictly indicate meaningful conceptual features (e.g., femininity or status). Because meaningful features yield regularities in usage, context spaces can proxy for concept spaces. However, context spaces also reflect surface regularities in language—e.g., syntax, morphology, dialect, and phraseology—which are irrelevant to most sociological investigations and can bias cultural measurement. We draw on our framework to propose best practices for measuring meaning with embeddings.",
    "url": "https://doi.org/10.1146/annurev-soc-090324-024027",
    "doi": "https://doi.org/10.1146/annurev-soc-090324-024027",
    "filter": 0,
    "journal_full": "Annual Review of Sociology"
  },
  {
    "discipline": "multidisciplinary",
    "title": "Testing for completions that simulate altruism in early language models",
    "authors": "Tim Johnson, Nick Obradovich",
    "abstract": "Altruism underlies cooperative behaviours that facilitate social complexity. In late 2022 and early 2023, we tested whether particular large language models—then in widespread use—generated completions that simulated altruism when prompted with text inputs similar to those used in ‘dictator game’ experiments measuring human altruism. Here we report that one model in our initial study set—OpenAI’s text-davinci-003—consistently generated completions that simulated payoff maximization in a non-social decision task yet simulated altruism in dictator games. Comparable completions appeared when we replicated our experiments, altered prompt phrasing, varied model parameters, altered currencies described in the prompt and studied a subsequent model, GPT-4. Furthermore, application of explainable artificial intelligence techniques showed that results changed little when instructing the system to ignore past research on the dictator or ultimatum games but changed noticeably when instructing the system to focus on the needs of particular participants in a simulated social encounter.",
    "url": "https://doi.org/10.1038/s41562-025-02258-7",
    "doi": "https://doi.org/10.1038/s41562-025-02258-7",
    "filter": 0,
    "journal_full": "Nature Human Behaviour"
  },
  {
    "discipline": "multidisciplinary",
    "title": "Semantic change in adults is not primarily a generational phenomenon",
    "authors": "Gaurav Kamath, Michelle Yang, Siva Reddy, Morgan Sonderegger, Dallas Card",
    "abstract": "A central question in the study of language change is whether or not such change is generational. If a language changes over time generation-by-generation, the process looks as follows: New generations of speakers introduce innovations, while older speakers conserve their usage patterns, and the language changes as new generations replace older ones. At the opposite extreme, language change could be a zeitgeist phenomenon, in which changes are universally adopted by speakers simultaneously, regardless of age or generational cohort. This paper asks this question in the context of word meaning change. We analyze meaning change in over 100 words across more than 7.9 million U.S. congressional speeches, to observe whether, when a word sense rises or falls in prominence, adult speakers from different generations uniformly adopt it, or those from older generations conserve their prior usage. Using language model-based word sense induction methods, we identify different senses of each word, and then model the prevalence of each of these word senses as a function of time and speaker age. We find that most words show a small but statistically significant effect of speaker age; across almost 140 y of Congress, older speakers typically take longer than younger speakers to follow changes in word usage, but nevertheless do so within a few years. Our findings indicate that despite minor age-based differences, word meaning change among mature speakers is likely not a generational process, but rather a zeitgeist process, in which older adult speakers can readily adopt new word usage patterns.",
    "url": "https://doi.org/10.1073/pnas.2426815122",
    "doi": "https://doi.org/10.1073/pnas.2426815122",
    "filter": 0,
    "journal_full": "Proceedings of the National Academy of Sciences"
  },
  {
    "discipline": "multidisciplinary",
    "title": "AI–AI bias: Large language models favor communications generated by large language models",
    "authors": "Walter Laurito, Benjamin Davis, Peli Grietzer, Tomáš Gavenčiak, Ada Böhm, Jan Kulveit",
    "abstract": "Are large language models (LLMs) biased in favor of communications produced by LLMs, leading to possible antihuman discrimination? Using a classical experimental design inspired by employment discrimination studies, we tested widely used LLMs, including GPT-3.5, GPT-4 and a selection of recent open-weight models in binary choice scenarios. These involved LLM-based assistants selecting between goods (the goods we study include consumer products, academic papers, and film-viewings) described either by humans or LLMs. Our results show a consistent tendency for LLM-based AIs to prefer LLM-presented options. This suggests the possibility of future AI systems implicitly discriminating against humans as a class, giving AI agents and AI-assisted humans an unfair advantage.",
    "url": "https://doi.org/10.1073/pnas.2415697122",
    "doi": "https://doi.org/10.1073/pnas.2415697122",
    "filter": 0,
    "journal_full": "Proceedings of the National Academy of Sciences"
  }
]
