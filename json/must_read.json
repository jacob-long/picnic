[
  {
    "discipline": "communication",
    "title": "Mobilizer, demobilizer–or artefact? Measuring the influence of research designs on the direct effect of negative advertising on voter turnout in U.S. election campaigns",
    "authors": "Jürgen Maier",
    "url": "https://doi.org/10.1080/02650487.2025.2536907",
    "doi": "https://doi.org/10.1080/02650487.2025.2536907",
    "filter": 0,
    "journal_full": "International Journal of Advertising"
  },
  {
    "discipline": "communication",
    "title": "Eye-Tracking Research in Advertising Scholarship: A Review and Practical Guide",
    "authors": "Claire M. Segijn",
    "url": "https://doi.org/10.1080/00913367.2025.2528215",
    "doi": "https://doi.org/10.1080/00913367.2025.2528215",
    "filter": 0,
    "journal_full": "Journal of Advertising"
  },
  {
    "discipline": "communication",
    "title": "Media Exposure Diversity: An Empirical Explication",
    "authors": "Xinle Jia, Zhongdang Pan, Fangjing Tu",
    "url": "https://doi.org/10.1080/08838151.2025.2535391",
    "doi": "https://doi.org/10.1080/08838151.2025.2535391",
    "filter": 0,
    "journal_full": "Journal of Broadcasting & Electronic Media"
  },
  {
    "discipline": "communication",
    "title": "“Truth Sandwich” To Dispel Crisis Misinformation: Exploring the Separate and Combined Impacts of Inoculation, Narratives, and Stealing Thunder on Correcting Crisis Misinformation on Social Media",
    "authors": "Young Kim, Hyunji Dana Lim",
    "url": "https://doi.org/10.1080/15205436.2025.2534979",
    "doi": "https://doi.org/10.1080/15205436.2025.2534979",
    "filter": 0,
    "journal_full": "Mass Communication and Society"
  },
  {
    "discipline": "communication",
    "title": "Why Do You Feel That Way? Elaboration Questions and Feeling Heard in Political Talk",
    "authors": "Brittany Shaughnessy, Myiah Hutchens, Janet Coats, Ilyssa Mann, Caleb Wiegandt, Mónica Guzmán",
    "abstract": "Across two studies, the current work sought to understand the impact of elaboration questions in political discussion on perceptions of feeling heard and future discussion intentions. Participants were presented with a recorded video of a political conversation where we manipulated the presence and absence of elaboration questions in political conversations surrounding homelessness (Study 1) and abortion (Study 2). Results indicate the presence of elaboration questions increased perceptions of being heard and intentions to engage in discussion in the future. We also found significant indirect results where the relationship between elaboration questions and intentions to engage in future discussions was mediated by feeling heard. These findings were never moderated by whether participants agreed with the political stance taken in the conversation.",
    "url": "https://doi.org/10.17645/mac.9977",
    "doi": "https://doi.org/10.17645/mac.9977",
    "filter": 0,
    "journal_full": "Media and Communication"
  },
  {
    "discipline": "communication",
    "title": "Mapping and Measuring Listening in Public Communication Settings",
    "authors": "Tariq Choucair",
    "abstract": "Scholars have made advancements in how to interpret, with detailed measures, the different characteristics and levels of distinct listening practices used by individuals when they are deliberating (Scudder, 2020, 2022). However, listening is not only a practice that occurs directly, but also a broader phenomenon that occurs across the public sphere (Bächtiger &amp;amp; Parkinson, 2019; Ercan et al., 2019). Public discourse occurs across hybrid media systems (Chadwick, 2017) in complex discursive exchanges (Maia et al., 2023) as networks of publics interact (Bruns, 2023). Such complexity imposes challenges for research to properly understand listening at a macro level. In this article, I present how to map and measure listening at this broader level. I reconstruct the discussion on listening as a normative foundation for political communication, from which we derive three key listening elements: attentiveness, openness, and responsiveness. I outline how listening is measured in direct interactions, to then explain how it can be assessed in public communication and mediated interactions, from the perspective of who listens, who is (or is not) listened to, and the actual listening acts.",
    "url": "https://doi.org/10.17645/mac.10263",
    "doi": "https://doi.org/10.17645/mac.10263",
    "filter": 0,
    "journal_full": "Media and Communication"
  },
  {
    "discipline": "communication",
    "title": "Self-Reported Exposure and Beliefs About Misinformation Across a U.S. Presidential Election Cycle: Expressive Responding and Motivated Reasoning",
    "authors": "R. Kelly Garrett, Robert M. Bond, Erik C. Nisbet",
    "url": "https://doi.org/10.1080/10584609.2025.2532584",
    "doi": "https://doi.org/10.1080/10584609.2025.2532584",
    "filter": 0,
    "journal_full": "Political Communication"
  },
  {
    "discipline": "communication",
    "title": "Deepfakes or Synthetic Media? The Effect of Euphemisms for Labeling Technology on Risk and Benefit Perceptions",
    "authors": "Adrian Rauchfleisch, Daniel Vogler, Gabriele de Seta",
    "abstract": "The language used in public debates and in the news can influence how citizens perceive the risks and benefits of technology. While framing effects on technology perception are well understood, few studies have focused on the effects of specific terms used to describe technology. We analyze how the terms deepfake and synthetic media affect risk and benefit perceptions across application fields. Using Switzerland as a case, our manual content analysis ( n = 380 news articles) reveals a focus on risks in news coverage of deepfakes with minimal use of the term synthetic media. We then tested the effects of the terms on risk and benefit perceptions in a preregistered survey experiment (n = 736 participants). Term choice does not change perceived risks, but “synthetic media” significantly increases perceived benefits across application fields. As a theoretical contribution, we link our findings to the concept of euphemism, proposing that term choice should align with application fields to reflect the risks and benefits of technology. Overall, our study shows that the terms we use to label technology matter, especially for emerging technologies such as artificial intelligence.",
    "url": "https://doi.org/10.1177/20563051251350975",
    "doi": "https://doi.org/10.1177/20563051251350975",
    "filter": 0,
    "journal_full": "Social Media + Society"
  },
  {
    "discipline": "politics",
    "title": "A Waste of Time? Partisan Deliberative Bias as a Barrier to Political Crosstalk",
    "authors": "Bryan McLaughlin, Nathaniel Geiger, Pedro H. P. Rocha",
    "abstract": "Americans are increasingly unwilling to talk about politics with out-partisans. One potential barrier to such cross-cutting partisan conversations may be partisans’ tendency to stereotype out-partisans as lacking the deliberative traits necessary to have a productive conversation (i.e., partisan deliberative bias ). Here, three studies examine the presence of partisan deliberative bias, its relationship to cross-cutting political talk, and potential pathways to reducing partisan deliberative bias. Study 1 (two-wave panel; Wave-2 N = 695) provides evidence that partisans perceive out-partisans possess less deliberative traits than in-partisans and these perceptions are related to reduced cross-cutting political talk (at Time 2). Study 2 (experimental; N = 417) provides evidence that exposing individuals to more examples of out-partisans who display deliberative traits (vs. anti-deliberative traits) leads to increased perceptions that out-partisans possess deliberative traits, which is associated with greater willingness to engage in a political conversation. Study 3 (experimental; N = 825) provides evidence that a deliberative bias-correcting intervention can reduce stereotypes about out-party members’ deliberative traits. Further, findings from an alternative model that includes in-group favoritism suggest that perceptions of deliberative traits are significantly related to cross-cutting political talk even when accounting for affective polarization. Findings across all three studies are similar for Republican and Democratic participants. Taken holistically, these results highlight the prevalence of partisan deliberative bias, suggest that such bias reduces cross-cutting conversations, and provide preliminary evidence for the effectiveness of interventions to address this bias.",
    "url": "https://doi.org/10.1007/s11109-025-10068-w",
    "doi": "https://doi.org/10.1007/s11109-025-10068-w",
    "filter": 0,
    "journal_full": "Political Behavior"
  },
  {
    "discipline": "public opinion",
    "title": "An Experimental Comparison of Modular and Non-Modular Approaches for Administering Surveys via Smartphone Apps",
    "authors": "Christopher Antoun, Brady T West, Xin (Rosalynn) Yang, Syed Junaid M A Zaidi, Jennifer Sinibaldi",
    "abstract": "Lengthy web surveys can be burdensome for respondents to complete in a single session. This study experimentally examines the effects of different app-based surveys, some of which use a modular design, on perceived burden, breakoffs, and indicators of satisficing behaviors. Participants (n = 664) were randomly assigned to one of four groups: (1) a browser-based web survey (control group), (2) an app-based survey, (3) a modular app dividing the survey into seven parts, and (4) a sequential modular app releasing modules at 48-hour intervals. Our findings indicate that administering surveys via apps can reduce the perceived burden of the survey task and improve response quality. Additionally, we find weak evidence that releasing modules individually over time can further enhance response quality, although this approach results in increased breakoffs between modules. The implications of these findings for the use of research apps and modular surveys are discussed.",
    "url": "https://doi.org/10.1093/jssam/smaf008",
    "doi": "https://doi.org/10.1093/jssam/smaf008",
    "filter": 0,
    "journal_full": "Journal of Survey Statistics and Methodology"
  },
  {
    "discipline": "psychology",
    "title": "Side Effects of Experience-Sampling Protocols: A Systematic Analysis of How They Affect Data Quality, Data Quantity, and Bias in Study Results",
    "authors": "Thomas Reiter, Sophia Sakel, Julian Scharbert, Julian ter Horst, Maarten van Zalk, Mitja Back, Markus Bühner, Ramona Schoedel",
    "abstract": "In studies using the increasingly popular experience-sampling method (ESM), design decisions are often guided by theoretical or practical considerations. Yet limited empirical evidence exists on how these choices affect data quantity (e.g., response probabilities), data quality (e.g., response latency), and potential biases in study outcomes (e.g., characteristics of study variables). In a preregistered, 4-week study ( N = 395), we experimentally manipulated two key ESM protocol characteristics for sending ESM surveys: timing (fixed vs. varying times) and contingency (directly vs. indirectly after unlocking the smartphone). We evaluated the ESM protocols resulting from the combination of these two characteristics regarding different criteria: As hypothesized for contingency, indirect protocols resulted in higher response probabilities (increased data quantity). But they also led to higher response latencies (reduced data quality). Contrary to our expectations, the combined effect of contingency and timing did not significantly influence response probability. We also did not observe other effects of timing or contingency on data quality. In exploratory follow-up analyses, we discovered that timing significantly affected response probability and smartphone-usage behaviors, as measured by screen logs; however, these effects were likely attributable to time-of-day effects. Self-reported states showed no differences based on the chosen ESM protocol, and similar trends were found when correlating primary outcomes with external criteria, such as trait affect and well-being. Based on the study’s findings, we discuss the trade-offs that researchers should consider when choosing their ESM protocols to optimize data quantity, data quality, and biases in study outcomes.",
    "url": "https://doi.org/10.1177/25152459251347274",
    "doi": "https://doi.org/10.1177/25152459251347274",
    "filter": 0,
    "journal_full": "Advances in Methods and Practices in Psychological Science"
  },
  {
    "discipline": "psychology",
    "title": "From Embeddings to Explainability: A Tutorial on Large-Language-Model-Based Text Analysis for Behavioral Scientists",
    "authors": "Rudolf Debelak, Timo K. Koch, Matthias Aßenmacher, Clemens Stachl",
    "abstract": "Large language models (LLMs) are transforming research in psychology and the behavioral sciences by enabling advanced text analysis at scale. Their applications range from the analysis of social media posts to infer psychological traits to the automated scoring of open-ended survey responses. However, despite their potential, many behavioral scientists struggle to integrate LLMs into their research because of the complexity of text modeling. In this tutorial, we aim to provide an accessible introduction to LLM-based text analysis, focusing on the Transformer architecture. We guide researchers through the process of preparing text data, using pretrained Transformer models to generate text embeddings, fine-tuning models for specific tasks such as text classification, and applying interpretability methods, such as Shapley additive explanations and local interpretable model-agnostic explanations, to explain model predictions. By making these powerful techniques more approachable, we hope to empower behavioral scientists to leverage LLMs in their research, unlocking new opportunities for analyzing and interpreting textual data.",
    "url": "https://doi.org/10.1177/25152459251351285",
    "doi": "https://doi.org/10.1177/25152459251351285",
    "filter": 0,
    "journal_full": "Advances in Methods and Practices in Psychological Science"
  },
  {
    "discipline": "psychology",
    "title": "Posterior predictive checks for the detection of extreme response style",
    "authors": "Martijn Schoenmakers, Jesper Tijmstra, Jeroen Vermunt, Maria Bolsinova",
    "abstract": "Extreme response style (ERS), the tendency of participants to select extreme item categories regardless of the item content, has frequently been found to decrease the validity of Likert-type questionnaire results (e.g., Moors, European Journal of Work and Organizational Psychology , 21 , 271–298, 2012). For this reason, detecting ERS at both the group and individual levels is of paramount importance. While various approaches to detecting ERS exist, these may conflate ERS with the trait of interest, require additional questionnaires to be administered, or require the use of mixture or multidimensional IRT models. As an alternative approach to detecting ERS, Bayesian posterior predictive checks (PPCs) may be a viable option. Posterior predictive checking offers a highly customizable framework for detecting model misfit, which can be directly applied to frequently used unidimensional IRT models. Critically, the use of PPCs to detect ERS does not require strong assumptions regarding the nature of ERS, such as ERS being a continuous dimension or a categorical trait. In this paper, we thus apply PPCs to a generalized partial credit model to detect model misfit related to ERS on both the group and person levels. We propose various possible PPCs tailored to ERS, which are illustrated in an empirical example, and their performance in detecting ERS is examined under various conditions. Suggestions for practical applications are provided, and avenues for future research are explored.",
    "url": "https://doi.org/10.3758/s13428-025-02756-6",
    "doi": "https://doi.org/10.3758/s13428-025-02756-6",
    "filter": 0,
    "journal_full": "Behavior Research Methods"
  },
  {
    "discipline": "psychology",
    "title": "Bayesian sample size determination for longitudinal intervention studies with linear and log-linear growth",
    "authors": "Ulrich Lösener, Mirjam Moerbeek",
    "abstract": "A priori sample size determination (SSD) is essential for designing cost-efficient trials and in avoiding underpowered studies. In addition, reporting a solid justification for a certain sample size is required by most ethics committees and many funding agencies. Often, SSD is based on null hypothesis significance testing (NHST), an approach that has received severe criticism in the past decades. As an alternative, Bayesian hypothesis evaluation using Bayes factors has been developed. Bayes factors quantify the relative support in the data for a pair of competing hypotheses without suffering from some of the drawbacks of NHST. SSD for Bayesian hypothesis testing relies on simulations and has only been studied recently. Available software for this is limited to simple models such as ANOVA and the t  test, in which observations are assumed to be independent from each other. However, this assumption is rendered untenable in longitudinal experiments where observations are nested within individuals. In that case, a multilevel model should be used. This paper provides researchers with a valuable tool for performing SSD for multilevel models with longitudinal data in a Bayesian framework, along with the necessary theoretical background and concrete empirical examples. The open-source R function that enables researchers to tailor the simulation to their trial at hand can be found on the GitHub page of the first author.",
    "url": "https://doi.org/10.3758/s13428-025-02749-5",
    "doi": "https://doi.org/10.3758/s13428-025-02749-5",
    "filter": 0,
    "journal_full": "Behavior Research Methods"
  },
  {
    "discipline": "psychology",
    "title": "Watching movies in VR: A research ecosystem for the study of screen media effects",
    "authors": "Faith A. Delle, Gary Bente, Nolan Jahn, Juncheng Wu",
    "abstract": "We introduce a virtual reality (VR) research ecosystem for the study of screen media effects and present a study providing evidence for its usability and validity. The study tested whether responses to affect-laden films presented on a standard TV within a physical space can be replicated in a virtual environment. The virtual setting was developed using Vizard 7.0, an open-access and customizable solution for media research. Using a between-subjects design, 70 participants were randomly assigned to either a TV or VR condition. Both groups were exposed to the same set of nine movie clips, encompassing three emotional categories (scary, funny, sad). While participants in the TV condition watched the clips on a physical 65″ TV, participants in the VR condition watched the clips on a virtual screen in the VR living room using a Meta Quest 2 VR headset. Continuous ratings of perceived emotional intensity and physiological measures of arousal (skin conductance level, heart rate, pulse volume amplitude) served as dependent variables. Overall, results confirmed the convergent validity between the two experimental conditions, revealing high correlations for all process variables across all stimuli. Results also demonstrated distinct responses to the clips of different emotional tones that were consistent across the experimental conditions. The findings encourage the use of VR for the study of screen media effects, demonstrating convergent validity with real-world scenarios while offering significant advantages, such as standardization and portability of the experimental setup as well as high levels of experimental control over reception setting variables.",
    "url": "https://doi.org/10.3758/s13428-025-02750-y",
    "doi": "https://doi.org/10.3758/s13428-025-02750-y",
    "filter": 0,
    "journal_full": "Behavior Research Methods"
  },
  {
    "discipline": "psychology",
    "title": "Using two-sided messages to facilitate misinformation correction for strongly held beliefs",
    "authors": "Mengran Xu, Richard E. Petty",
    "url": "https://doi.org/10.1016/j.jesp.2025.104807",
    "doi": "https://doi.org/10.1016/j.jesp.2025.104807",
    "filter": 0,
    "journal_full": "Journal of Experimental Social Psychology"
  },
  {
    "discipline": "psychology",
    "title": "Threat Perceptions and Closeness to Refugees: A Three-Wave Longitudinal Study",
    "authors": "Zafer Özkan, Małgorzata Kossowska, Ewa Szumowska, Jolanta Perek-Białas, Paulina Szwed",
    "abstract": "This study examines the longitudinal interplay between individuals’ perceptions of two types of intergroup threats—realistic and symbolic—and their feelings of closeness toward Ukrainian war refugees, using a three-wave design and a random intercept cross-lagged panel model. By disentangling within-person dynamics from between-person effects, the findings reveal that stronger-than-usual feelings of closeness predicted reduced perceptions of both realistic and symbolic threats over time. Conversely, heightened perceptions of realistic threat significantly undermine feelings of closeness, whereas symbolic threat demonstrates no substantial influence on subsequent closeness. These results underscore the centrality of realistic threats, reflecting concerns such as economic competition and resource allocation strains, in shaping intergroup attitudes in the studied context. By distinguishing between within- and between-person variances, and adopting a longitudinal framework, this study provides novel insights into the mechanisms underlying intergroup relations, offering a robust empirical contribution to the field.",
    "url": "https://doi.org/10.1177/01461672251352899",
    "doi": "https://doi.org/10.1177/01461672251352899",
    "filter": 0,
    "journal_full": "Personality and Social Psychology Bulletin"
  },
  {
    "discipline": "psychology",
    "title": "Introspective Access or Retrospective Inference? Mind-Wandering Reports Are Shaped by Performance Feedback",
    "authors": "Naya Polychroni, Mahiko Konishi, Isa Steinecker, Devin B. Terhune",
    "abstract": "Most mind-wandering paradigms use self-reports following task performance, but the extent to which these reports are confounded by performance cues is unknown. In two experiments with adult human participants, we examined whether self-reports and confidence therein are influenced by performance indicators during visual metronome response tasks. In Experiment 1 ( N = 40), sham feedback modulated reports independently of behavioral performance with participants more likely to report mind wandering after incorrect than correct sham feedback. In Experiment 2 ( N = 111), we replicated this pattern using a more implicit manipulation of perceived performance—a surreptitious delay in the onset of response targets. Participants were more likely to report mind wandering after this delay than they were in control trials. In both experiments, confidence in on-task reports was lower when the corresponding indicator (falsely) implied poor performance. These findings suggest that mind-wandering reports and experiential state confidence are partly confounded by performance monitoring and have implications for experience-sampling methodologies.",
    "url": "https://doi.org/10.1177/09567976251349816",
    "doi": "https://doi.org/10.1177/09567976251349816",
    "filter": 0,
    "journal_full": "Psychological Science"
  },
  {
    "discipline": "psychology",
    "title": "Becoming an Ostrich: The Development of Information Avoidance",
    "authors": "Radhika Santhanagopalan, Jane L. Risen, Katherine D. Kinzler",
    "abstract": "Adults selectively avoid useful information. We examined the development of information avoidance in 5- to 10-year-old American children ( N = 320). In Experiment 1, children considered scenarios that might elicit information avoidance: protecting against negative emotions, maintaining perceptions of likeability and competence, preserving beliefs and preferences, and acting in self-interest. When a motivation for avoidance was present, children were more likely to avoid learning information, particularly with age. Experiment 2 presented the self-interest scenario (a moral “wiggle room” task) involving real payoffs. Although children could reveal their partner’s payoff without cost, older children capitalized on moral “wiggle room” by avoiding this information and choosing the self-interested payoff. In Experiment 3, we considered conditions under which even young children might avoid information, finding that they too avoided information when explicitly encouraged to protect their emotions. Additional qualitative findings probed children’s open-ended responses about why people seek and avoid information. Together, these experiments document the origins of information avoidance.",
    "url": "https://doi.org/10.1177/09567976251344551",
    "doi": "https://doi.org/10.1177/09567976251344551",
    "filter": 0,
    "journal_full": "Psychological Science"
  },
  {
    "discipline": "psychology",
    "title": "“Stop the Count!”—How Reporting Partial Election Results Fuels Beliefs in Election Fraud",
    "authors": "André Vaz, Moritz Ingendahl, André Mata, Hans Alves",
    "abstract": "In seven studies, we investigated how reporting partial vote counts influences perceptions of election legitimacy. Beliefs in election fraud, as in the 2020 U.S. presidential election, may be fueled by the cumulative redundancy bias (CRB), which skews perceptions toward early leaders in partial vote counts. In line with this prediction, participants (Prolific adult participants from the United States and the United Kingdom) consistently rated early leaders more favorably and were more likely to suspect fraud when the eventual winner gained a late lead. This effect persisted across simulated elections (Studies 1–3) and real-world vote counts from the 2020 election in Georgia (Study 4). It is important to note that fraud suspicions already arose before the count was completed (Study 5) and persisted despite explanatory interventions (Study 6). Partisanship did not eliminate the CRB’s influence on fraud beliefs (Study 7). Our findings suggest that the sequential reporting of vote counts may amplify false perceptions of election fraud and could be mitigated by revising how results are communicated.",
    "url": "https://doi.org/10.1177/09567976251355594",
    "doi": "https://doi.org/10.1177/09567976251355594",
    "filter": 0,
    "journal_full": "Psychological Science"
  },
  {
    "discipline": "sociology",
    "title": "Evaluating Methods to Prevent and Detect Inattentive Respondents in Web Surveys",
    "authors": "Lukas Olbrich, Joseph W. Sakshaug, Eric Lewandowski",
    "abstract": "Inattentive respondents pose a substantial threat to data quality in web surveys. We evaluate methods for preventing and detecting inattentive respondents. First, we test the effect of asking respondents to commit to providing high-quality responses at the beginning of the survey on various data quality measures. Second, we compare the proportion of flagged respondents for two versions of an attention check item instructing them to select a specific response versus leaving the item blank. Third, we propose a timestamp-based cluster analysis approach that identifies clusters of respondents who exhibit different speeding behaviors. Our findings show that the commitment pledge had no effect on the data quality measures. Instructing respondents to leave the item blank significantly increased the rate of flagged respondents (by 16.8 percentage points). The timestamp-based clustering approach efficiently identified clusters of likely inattentive respondents. Lastly, we show that inattentive respondents can have substantial impacts on substantive analyses.",
    "url": "https://doi.org/10.1177/00491241251345457",
    "doi": "https://doi.org/10.1177/00491241251345457",
    "filter": 0,
    "journal_full": "Sociological Methods & Research"
  },
  {
    "discipline": "multidisciplinary",
    "title": "Feature-based reward learning shapes human social learning strategies",
    "authors": "David Schultner, Lucas Molleman, Björn Lindström",
    "abstract": "Human adaptation depends on individuals strategically choosing whom to learn from. A mosaic of social learning strategies—such as copying majorities or successful others—has been identified. Influential theories conceive of these strategies as fixed heuristics, independent of experience. However, such accounts cannot explain the flexibility and individual variability prevalent in social learning. Here we advance a domain-general reward learning framework that provides a unifying mechanistic account of pivotal social learning strategies. We first formalize how individuals learn to associate social features (for example, others’ behaviour or success) with reward. Across six experiments ( n = 1,941), we show that people flexibly adjust their social learning in response to experienced rewards. Agent-based simulations further demonstrate how this learning process gives rise to key social learning strategies across a range of environments. Our findings suggest that people learn how to learn from others, enabling adaptive knowledge to spread dynamically throughout societies.",
    "url": "https://doi.org/10.1038/s41562-025-02269-4",
    "doi": "https://doi.org/10.1038/s41562-025-02269-4",
    "filter": 0,
    "journal_full": "Nature Human Behaviour"
  },
  {
    "discipline": "multidisciplinary",
    "title": "Semantic change in adults is not primarily a generational phenomenon",
    "authors": "Gaurav Kamath, Michelle Yang, Siva Reddy, Morgan Sonderegger, Dallas Card",
    "abstract": "A central question in the study of language change is whether or not such change is generational. If a language changes over time generation-by-generation, the process looks as follows: New generations of speakers introduce innovations, while older speakers conserve their usage patterns, and the language changes as new generations replace older ones. At the opposite extreme, language change could be a zeitgeist phenomenon, in which changes are universally adopted by speakers simultaneously, regardless of age or generational cohort. This paper asks this question in the context of word meaning change. We analyze meaning change in over 100 words across more than 7.9 million U.S. congressional speeches, to observe whether, when a word sense rises or falls in prominence, adult speakers from different generations uniformly adopt it, or those from older generations conserve their prior usage. Using language model-based word sense induction methods, we identify different senses of each word, and then model the prevalence of each of these word senses as a function of time and speaker age. We find that most words show a small but statistically significant effect of speaker age; across almost 140 y of Congress, older speakers typically take longer than younger speakers to follow changes in word usage, but nevertheless do so within a few years. Our findings indicate that despite minor age-based differences, word meaning change among mature speakers is likely not a generational process, but rather a zeitgeist process, in which older adult speakers can readily adopt new word usage patterns.",
    "url": "https://doi.org/10.1073/pnas.2426815122",
    "doi": "https://doi.org/10.1073/pnas.2426815122",
    "filter": 0,
    "journal_full": "Proceedings of the National Academy of Sciences"
  },
  {
    "discipline": "multidisciplinary",
    "title": "AI–AI bias: Large language models favor communications generated by large language models",
    "authors": "Walter Laurito, Benjamin Davis, Peli Grietzer, Tomáš Gavenčiak, Ada Böhm, Jan Kulveit",
    "abstract": "Are large language models (LLMs) biased in favor of communications produced by LLMs, leading to possible antihuman discrimination? Using a classical experimental design inspired by employment discrimination studies, we tested widely used LLMs, including GPT-3.5, GPT-4 and a selection of recent open-weight models in binary choice scenarios. These involved LLM-based assistants selecting between goods (the goods we study include consumer products, academic papers, and film-viewings) described either by humans or LLMs. Our results show a consistent tendency for LLM-based AIs to prefer LLM-presented options. This suggests the possibility of future AI systems implicitly discriminating against humans as a class, giving AI agents and AI-assisted humans an unfair advantage.",
    "url": "https://doi.org/10.1073/pnas.2415697122",
    "doi": "https://doi.org/10.1073/pnas.2415697122",
    "filter": 0,
    "journal_full": "Proceedings of the National Academy of Sciences"
  },
  {
    "discipline": "multidisciplinary",
    "title": "Understanding the success and failure of online political debate: Experimental evidence using large language models",
    "authors": "Tobias Heide-Jørgensen, Gregory Eady, Anne Rasmussen",
    "abstract": "Online political debate is frequently lamented for being toxic, partisan, and counterproductive. However, we know little about how core elements of political debate (justification, tone, willingness to compromise, and partisanship) affect its quality. Using text-based treatments experimentally manipulated with a large language model, we test how these elements causally affect the quality of open-text responses about issues important to the US and UK public. We find substantial evidence that differences in justification, tone, and willingness to compromise, but not partisanship, affect the quality of subsequent discourse. Combined, these elements increase the probability of high-quality responses by roughly 1.6 to 2 times and substantially increase openness to alternative viewpoints. Despite the ability to bring about substantial changes in discourse quality, we find no evidence of changes in political attitudes themselves. Our findings demonstrate how adapting approaches to online debate can foster healthy democratic interactions but have less influence on changing minds.",
    "url": "https://doi.org/10.1126/sciadv.adv7864",
    "doi": "https://doi.org/10.1126/sciadv.adv7864",
    "filter": 0,
    "journal_full": "Science Advances"
  }
]
