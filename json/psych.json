{
  "update": "2025-10-13",
  "content": [
    {
      "journal_full": "Advances in Methods and Practices in Psychological Science",
      "journal_short": "AMPPS",
      "articles": [
        {
          "title": "Identifying Careless Survey Respondents Through Machine Learning Using Responses to a Gibberish Scale",
          "authors": "Leah Bloy, Yehezkel Resheff, Avraham Kluger, Nechumi Malovicki-Yaffe",
          "abstract": "Invalid responses pose a significant risk of distorting survey data, compromising statistical inferences, and introducing errors in conclusions drawn from surveys. Given the pivotal role of surveys in research, development, and decision-making, it is imperative to identify careless survey respondents. The existing literature on this subject comprises two primary categories of approaches: methods that rely on survey items and methods involving post hoc analyses. The latter, which does not demand preemptive preparation, predominantly incorporates statistical techniques or metadata analysis aimed at identifying distinct response patterns that are associated with careless responses. However, several inherent limitations limit the precise identification of careless respondents. One notable challenge is the lack of consensus concerning the thresholds to use for the various measures. Furthermore, each method is designed to detect a specific response pattern associated with carelessness, leading to conflicting outcomes. In this article, we seek to assess the efficacy of the existing methods using a novel survey methodology encompassing responses to both meaningful and meaningless gibberish scales in which the latter compels respondents to answer without considering item content. Using this approach, we propose the application of machine learning to identify careless survey respondents. Our findings underscore the efficacy of a methodology using supervised machine learning combined with unique gibberish data as a potent method for the identification of careless respondents, aligning with and outperforming other approaches in terms of effectiveness and versatility.",
          "url": "https://doi.org/10.1177/25152459251378420",
          "doi": "https://doi.org/10.1177/25152459251378420",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Behavior Research Methods",
      "journal_short": "BRM",
      "articles": [
        {
          "title": "Building a construct-valid battery of performance and self-report indicators of sustained attention consistency",
          "authors": "Matthew S. Welhaf, Matt E. Meier, Michael J. Kane",
          "abstract": "Previous work has argued that the ability to sustain attention consistency can be best modeled as the individual-difference covariation in objective performance-based measures (e.g., reaction-time [RT] variability; accuracy) and self-report measures of task-unrelated thought (TUT). Latent variable studies demonstrate that a general, higher-order attention consistency factor correlates more strongly with nomological network constructs than do either lower-order, measurement-specific factors. The present study aimed to replicate and extend this measurement approach by building a construct-valid battery of sustained attention consistency tasks and testing associations with the conative factors of task interest and success motivation. We analyzed data from 402 subjects who completed a battery of seven attention-consistency functions and found that the hierarchical model provided an adequate fit to the data. Further, attention-consistency associations with motivation and interest, while evident with the lower-order factors, were again stronger with the general higher-order factor (and each conative factor predicted unique variance in general attention consistency in structural regression models). We also refined our task battery by removing poor-performing indicators and demonstrated similar patterns of correlations among the attention and conative factors. We suggest that studies examining attention consistency should use a combination of performance and self-report indicators to capture its individual-differences variation in the most construct valid way. We finally provide recommendations on which tasks and measures might be most useful when measuring sustained attention consistency in future research.",
          "url": "https://doi.org/10.3758/s13428-025-02798-w",
          "doi": "https://doi.org/10.3758/s13428-025-02798-w",
          "filter": 0
        },
        {
          "title": "Normal and nonnormal polynomial regression mixture modeling for differential congruence effects: A simulation and tutorial",
          "authors": "Eunsook Kim, Radhika Sundar, Emma Evudottir, Minjung Kim, Robert Dedrick, Junyeong Yang, Nathaniel von der Embse",
          "url": "https://doi.org/10.3758/s13428-025-02821-0",
          "doi": "https://doi.org/10.3758/s13428-025-02821-0",
          "filter": 0
        },
        {
          "title": "Movement tracking of psychological processes: A tutorial using mousetrap",
          "authors": "Dirk U. Wulff, Pascal J. Kieslich, Felix Henninger, Jonas M. B. Haslbeck, Michael Schulte-Mecklenbeck",
          "abstract": "Movement tracking is a novel process-tracing method that promises unique access to the temporal dynamics of psychological processes. The method involves high-resolution tracking of a hand or handheld device (e.g., a computer mouse) while it is used to make a choice. In contrast to other process-tracing methods, which mostly focus on information acquisition, movement tracking focuses on the processes of information integration and preference formation. In this article, we present a tutorial on movement tracking of psychological processes with the mousetrap R package. We address all steps of the research process, from design to interpretation, with a particular focus on data processing and analysis and featuring both established and novel approaches. Using a representative working example, we demonstrate how the various steps of movement-tracking analysis can be implemented with mousetrap and provide thorough explanations of their theoretical background and interpretation. Finally, we present a list of recommendations to assist researchers in addressing their own research questions using movement tracking of psychological processes.",
          "url": "https://doi.org/10.3758/s13428-025-02695-2",
          "doi": "https://doi.org/10.3758/s13428-025-02695-2",
          "filter": 0
        },
        {
          "title": "Towards scalable and reliable coding of semantic property norms: ChatGPT vs. an improved AC-PLT",
          "authors": "Diego Ramos, Sebastián Moreno, Enrique Canessa, Sergio E. Chaigneau",
          "url": "https://doi.org/10.3758/s13428-025-02838-5",
          "doi": "https://doi.org/10.3758/s13428-025-02838-5",
          "filter": 0
        },
        {
          "title": "A web-based mouse-tracking task for early perceptual language processing",
          "authors": "Holger Mitterer",
          "abstract": "The study of language processing requires data from a wide range of languages but also data that are free from demand characteristics and meta-linguistic strategies. While eye-tracking has been successfully used to address the later issue, pragmatically, eye-tracking is often difficult to achieve with less well-studied languages. Therefore, the current paper presents a web-based mouse-tracking task that generates data that seem to reflect early perceptual processes similar to eye-tracking but which can be performed remotely. The task uses a set-up similar to early video games to entice participants to use language input as early as possible. The data presented here replicate an earlier eye-tracking study focusing on how reduced words are recognized. Fillers from the same study are also used, which show that the paradigm also reflects predictive semantic processing. It is concluded that the paradigm can be used to investigate lexical access, prosodic processing, and predictive semantic processing.",
          "url": "https://doi.org/10.3758/s13428-025-02827-8",
          "doi": "https://doi.org/10.3758/s13428-025-02827-8",
          "filter": 0
        },
        {
          "title": "Crowdsourced and AI-generated age-of-acquisition (AoA) norms for vocabulary in print: Extending the Kuperman et al. (2012) norms",
          "authors": "Clarence Green, Anthony Pak-Hin Kong, Marc Brysbaert, Kathleen Keogh",
          "abstract": "This paper revisits the age-of-acquisition (AoA) norms of Kuperman et al. (2012). Three studies were conducted. Study 1 reports a crowdsourcing ‘megastudy’ obtaining 790,024 estimates from participants with the age they could first read and write 11,074 early acquired words from Kuperman et al. (2012). The study aimed to differentiate between oral language receptive AoA and print-based AoA. The results correlate well with the original estimates, offering, as hypothesized, higher AoAs for reading/writing. These are released as supplements to the original norms. Study 2 explored the potential of large language models (LLMs), specifically GPT-4o, to replicate these crowdsourced AoA estimates. The findings indicated a strong correlation between AI-generated estimates and human judgments, showing the utility of AI in estimating AoA and developing norms for psycholinguistic and educational research in lieu of crowdsourcing. Study 3 leveraged AI to extend estimates to all well-known words in Kuperman et al. (2012) and the English Crowdsourcing Project (ECP). Study 3 also investigated a trained model fine-tuned on 2000 ratings from Kuperman et al. (2012). Fine-tuning increased alignment with human ratings, though comparisons with untrained models suggested that fine-tuning is not essential in English for obtaining useful AoA estimates. Both trained and untrained AI-generated norms correlated highly with human ratings and performed well in accounting for word processing times and accuracy in regressions. Uses and limitations of the AI estimates are discussed. All resources are made available in the Open Science Framework and can be used freely for research and education.",
          "url": "https://doi.org/10.3758/s13428-025-02843-8",
          "doi": "https://doi.org/10.3758/s13428-025-02843-8",
          "filter": 0
        },
        {
          "title": "Can you beat the music? Validation of a gamified rhythmic training in children with ADHD",
          "authors": "Kevin Jamey, Hugo Laflamme, Nicholas E. V. Foster, Simon Rigoulot, Sarah Lippé, Sonja A. Kotz, Simone Dalla Bella",
          "url": "https://doi.org/10.3758/s13428-025-02802-3",
          "doi": "https://doi.org/10.3758/s13428-025-02802-3",
          "filter": 0
        },
        {
          "title": "Applying Bayesian checks of cancellation axioms for interval scaling in limited samples",
          "authors": "Sanford R. Student, Wyatt S. Read",
          "abstract": "Interval scales are frequently assumed in educational and psychological research involving latent variables, but are rarely verified. This paper outlines methods for investigating the interval scale assumption when fitting the Rasch model to item response data. We study a Bayesian method for evaluating an item response dataset’s adherence to the cancellation axioms of additive conjoint measurement under the Rasch model, and compare the extent to which the axiom of double cancellation holds in the data at sample sizes of 250 and 1000 with varying test lengths, difficulty spreads, and levels of adherence to the Rasch model in the data-generating process. Because the statistic produced by the procedure is not directly interpretable as an indicator of whether an interval scale can be established, we develop and evaluate procedures for bootstrapping a null distribution of violation rates against which to compare results. At a sample size of 250, the method under investigation is not well powered to detect the violations of interval scaling that we simulate, but the procedure works quite consistently at N = 1000. That is, at moderate but achievable sample sizes, empirical tests for interval scaling are indeed possible.",
          "url": "https://doi.org/10.3758/s13428-025-02844-7",
          "doi": "https://doi.org/10.3758/s13428-025-02844-7",
          "filter": 0
        },
        {
          "title": "Detecting mind wandering via EEG and facial video features",
          "authors": "Shaohua Tang, Chunbo Jiang, Zheng Li",
          "url": "https://doi.org/10.3758/s13428-025-02847-4",
          "doi": "https://doi.org/10.3758/s13428-025-02847-4",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Computers in Human Behavior",
      "journal_short": "CHB",
      "articles": [
        {
          "title": "Tinder for teens: Youth digital intimate cultures and tech facilitated violence on Snapchat",
          "authors": "Betsy Milne, Jessica Ringrose, Tanya Horeck, Kaitlynn Mendes",
          "url": "https://doi.org/10.1016/j.chb.2025.108823",
          "doi": "https://doi.org/10.1016/j.chb.2025.108823",
          "filter": 0
        },
        {
          "title": "The quantification of the gaming experience: Self-tracking practices and game metrics among casual players, esports players, and streamers",
          "authors": "Amon Rapp, Arianna Boldi",
          "url": "https://doi.org/10.1016/j.chb.2025.108826",
          "doi": "https://doi.org/10.1016/j.chb.2025.108826",
          "filter": 0
        },
        {
          "title": "Rethinking social media and mental health: The role of emotion regulation difficulties",
          "authors": "Daniel J. Brown, Riley Scott, Renee Ireland, Jacqueline Harness, Daniel J. Phipps, Jacob J. Keech",
          "url": "https://doi.org/10.1016/j.chb.2025.108825",
          "doi": "https://doi.org/10.1016/j.chb.2025.108825",
          "filter": 0
        },
        {
          "title": "How Gaming Goal Pursuit and Expert-Rated Computer Game Features Interact to Affect Human Game Use Behavior",
          "authors": "Gen-Yih Liao, Shih-I Tai, Ng Nga Yan, T.C.E. Cheng, Ching-I Teng",
          "url": "https://doi.org/10.1016/j.chb.2025.108819",
          "doi": "https://doi.org/10.1016/j.chb.2025.108819",
          "filter": 0
        },
        {
          "title": "AI makes you smarter but none the wiser: The disconnect between performance and metacognition",
          "authors": "Daniela Fernandes, Steeven Villa, Salla Nicholls, Otso Haavisto, Daniel Buschek, Albrecht Schmidt, Thomas Kosch, Chenxinran Shen, Robin Welsch",
          "url": "https://doi.org/10.1016/j.chb.2025.108779",
          "doi": "https://doi.org/10.1016/j.chb.2025.108779",
          "filter": 0
        },
        {
          "title": "Beyond Algorithm Aversion: The Impact of Psychological Readiness on Algorithmic Advice",
          "authors": "Hyoseok Kim",
          "url": "https://doi.org/10.1016/j.chb.2025.108824",
          "doi": "https://doi.org/10.1016/j.chb.2025.108824",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Experimental Social Psychology",
      "journal_short": "JESP",
      "articles": [
        {
          "title": "Beyond the basic six, static, and WERID: Exploring the range of emotions conveyed by facial expressions",
          "authors": "Zhihe Pan, Hweemin Tan, Siqi Liu, Xia Fang",
          "url": "https://doi.org/10.1016/j.jesp.2025.104836",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104836",
          "filter": 0
        },
        {
          "title": "Intentions versus outcomes: Determinants of costly third-party interventions in fairness maintenance",
          "authors": "Mei Chen, Ruqian Zhang, Yangzhuo Li, Jieqiong Liu, Xianchun Li",
          "url": "https://doi.org/10.1016/j.jesp.2025.104838",
          "doi": "https://doi.org/10.1016/j.jesp.2025.104838",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Multivariate Behavioral Research",
      "journal_short": "MBR",
      "articles": [
        {
          "title": "Standardized Estimates of Second-Order Latent Growth Models: A Comparison of Alternative Latent-Standardization Methods",
          "authors": "Yifan Wang, Zhonglin Wen, Kit-Tai Hau, Tonglin Jin",
          "url": "https://doi.org/10.1080/00273171.2025.2543240",
          "doi": "https://doi.org/10.1080/00273171.2025.2543240",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Organizational Research Methods",
      "journal_short": "ORM",
      "articles": [
        {
          "title": "Understanding Relative Differences with Magnitude-Based Hypotheses: A Methodological Conceptualization and Data Illustration",
          "authors": "Dane P. Blevins, David J. Skandera, Roberto Ragozzino",
          "abstract": "Our paper provides a conceptualization of magnitude-based hypotheses (MBHs). We define an MBH as a specific type of hypothesis that tests for relative differences in the independent impact (i.e., effect size difference) of at least two explanatory variables on a given outcome. We reviewed 1,715 articles across eight leading management journals and found that nearly 10% (165) of articles feature an MBH, employing 41 distinct methodological approaches to test them. However, approximately 40% of these papers show missteps in the post-estimation process required to evaluate MBHs. To address this issue, we offer a conceptual framework, an empirical illustration using Bayesian analysis and frequentist statistics, and a decision-tree guideline that outlines key steps for evaluating MBHs. Overall, we contribute a framework for applying MBHs, demonstrating how they can shift theoretical inquiry from binary questions of whether an effect exists, to more comparative questions about how much a construct matters,compared to what, and under which conditions.",
          "url": "https://doi.org/10.1177/10944281251377139",
          "doi": "https://doi.org/10.1177/10944281251377139",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Personality and Social Psychology Bulletin",
      "journal_short": "PSPB",
      "articles": [
        {
          "title": "The Underestimation of Transgender Women’s Vulnerability to Workplace Sexual Harassment",
          "authors": "Bryn Bandt-Law, Nathan N. Cheek, Jessica J. Glazier, Kristina R. Olson, Cheryl R. Kaiser",
          "abstract": "Despite experiencing sexual harassment more frequently and more severely than cisgender women, transgender women survivors’/victims’ experiences of workplace sexual harassment are often omitted or ignored. Drawing from theorizing on victim prototypes and perceptions of sexual harassment, we show across six studies (total N = 2,022) that people incorrectly believe that transgender women are less likely to experience workplace sexual harassment compared to cisgender women. This effect is stronger among individuals who deny that transgender women are, in fact, women. We also show that people perceive harassment claims from transgender women who experience unwanted advances to be less credible than identical claims from cisgender women. Perceptions that transgender women are unlikely and non-credible victims of sexual harassment have important implications for understanding the erasure and neglect of transgender women survivors and the obstruction of transgender women’s civil rights.",
          "url": "https://doi.org/10.1177/01461672251368955",
          "doi": "https://doi.org/10.1177/01461672251368955",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Psychological Methods",
      "journal_short": "PM",
      "articles": [
        {
          "title": "The repeated adjustment of measurement protocols method for developing high-validity text classifiers.",
          "authors": "Alex Goddard, Alex Gillespie",
          "url": "https://doi.org/10.1037/met0000787",
          "doi": "https://doi.org/10.1037/met0000787",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Psychology of Popular Media",
      "journal_short": "PPM",
      "articles": [
        {
          "title": "Media versus meditation: A comparison of the stress-relieving benefits of multiple media experiences.",
          "authors": "Robin L. Nabi, Nathan Walter, Jessica Gall Myrick, Minghui Wang, Blake Ekeler",
          "url": "https://doi.org/10.1037/ppm0000623",
          "doi": "https://doi.org/10.1037/ppm0000623",
          "filter": 0
        }
      ],
      "articles_hidden": []
    }
  ]
}
