{
  "update": "2024-09-30",
  "content": [
    {
      "journal_full": "Journal of Elections, Public Opinion and Parties",
      "journal_short": "JEPOP",
      "articles": [
        {
          "title": "Revisiting citizen preferences for who should govern and how. the case of cross-national surveys",
          "authors": "Adrián del Río",
          "url": "http://dx.doi.org/10.1080/17457289.2024.2409641",
          "doi": "10.1080/17457289.2024.2409641",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Journal of Survey Statistics and Methodology",
      "journal_short": "JSSAM",
      "articles": [
        {
          "title": "Real-World Data Versus Probability Surveys for Estimating Health Conditions at the State Level",
          "authors": "David A Marker, Charity Hilton, Jacob Zelko, Jon Duke, Deborah Rolka, Rachel Kaufmann, Richard Boyd",
          "abstract": "Government statistical offices worldwide are under pressure to produce statistics rapidly and for more detailed geographies, to compete with unofficial estimates available from web-based big data sources or from private companies. Commonly suggested sources of improved health information are electronic health records and medical claims data. These data sources are collectively known as real-world data (RWD) because they are generated from routine health care processes, and they are available for millions of patients. It is clear that RWD can provide estimates that are more timely and less expensive to produce—but a key question is whether or not they are very accurate. To test this, we took advantage of a unique health data source that includes a full range of sociodemographic variables and compared estimates using all of those potential weighting variables versus estimates derived when only age and sex are available for weighting (as is common with most RWD sources). We show that not accounting for other variables can produce misleading and quite inaccurate health estimates.",
          "url": "http://dx.doi.org/10.1093/jssam/smae036",
          "doi": "10.1093/jssam/smae036",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Politics, Groups, and Identities",
      "journal_short": "PGI",
      "articles": [
        {
          "title": "Organizational leaders and intersectional advocacy",
          "authors": "Maraam A. Dwidar, Kathleen Marchetti, Dara Z. Strolovitch",
          "url": "http://dx.doi.org/10.1080/21565503.2024.2402318",
          "doi": "10.1080/21565503.2024.2402318",
          "filter": 0
        }
      ],
      "articles_hidden": []
    },
    {
      "journal_full": "Social Science Computer Review",
      "journal_short": "SSCR",
      "articles": [
        {
          "title": "Large Language Models Outperform Expert Coders and Supervised Classifiers at Annotating Political Social Media Messages",
          "authors": "Petter Törnberg",
          "abstract": "Instruction-tuned Large Language Models (LLMs) have recently emerged as a powerful new tool for text analysis. As these models are capable of zero-shot annotation based on instructions written in natural language, they obviate the need of large sets of training data—and thus bring potential paradigm-shifting implications for using text as data. While the models show substantial promise, their relative performance compared to human coders and supervised models remains poorly understood and subject to significant academic debate. This paper assesses the strengths and weaknesses of popular fine-tuned AI models compared to both conventional supervised classifiers and manual annotation by experts and crowd workers. The task used is to identify the political affiliation of politicians based on a single X/Twitter message, focusing on data from 11 different countries. The paper finds that GPT-4 achieves higher accuracy than both supervised models and human coders across all languages and country contexts. In the US context, it achieves an accuracy of 0.934 and an inter-coder reliability of 0.982. Examining the cases where the models fail, the paper finds that the LLM—unlike the supervised models—correctly annotates messages that require interpretation of implicit or unspoken references, or reasoning on the basis of contextual knowledge—capacities that have traditionally been understood to be distinctly human. The paper thus contributes to our understanding of the revolutionary implications of LLMs for text analysis within the social sciences.",
          "url": "http://dx.doi.org/10.1177/08944393241286471",
          "doi": "10.1177/08944393241286471",
          "filter": 0
        },
        {
          "title": "Why People Accept Mental Health-Related Misinformation: Role of Social Media Metrics in Users’ Information Processing",
          "authors": "Shiyi Zhang, Huiyu Zhou, Yimei Zhu",
          "abstract": "Drawing on dual-process theories, this study aims to investigate the factors associated with social media users’ acceptance of mental health-related misinformation (MHRM). We conducted a case study of Chinese microblogging Weibo on conversations that emerged following a publicised celebrity suicide of South Korean superstar Sulli. This incident sparked an extensive discussion on mental health issues as Sulli was reported to have suffered from depression prior to her death. Whilst previous studies on users’ information acceptance mainly adopted survey methods, our study employs a mixed-method approach (i.e. computational data collection method, content analysis and statistical analysis), which opens up new directions to utilise secondary social media data. We identified MHRM from the discussions on Weibo and labelled the responses to the misinformation as whether they indicate an acceptance of the MHRM. Binary logistic regression was used to examine the associations of receivers’ acceptance of MHRM with its information features (e.g. number of likes) and information sources (e.g. gender). Inconsistent with previous studies, our findings suggest that MHRM is less likely to be accepted when published by male users, underscoring the context-specific nature of heuristic cues. This study also revealed some novel findings, such as MHRM with more pictures or with more words is less likely to be accepted. A theoretical model was proposed based on the findings, which highlights the importance of heuristic cues and individuals’ pre-existing knowledge in information processing.",
          "url": "http://dx.doi.org/10.1177/08944393241287791",
          "doi": "10.1177/08944393241287791",
          "filter": 0
        }
      ],
      "articles_hidden": []
    }
  ]
}
